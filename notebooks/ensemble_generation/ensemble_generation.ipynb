{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from __future__ import annotations",
   "id": "99ee032aadb0aa4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import argparse\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple"
   ],
   "id": "f6fba0bb1860d7e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ],
   "id": "e52757cf977ddc59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from gerrychain import GeographicPartition, Graph, MarkovChain\n",
    "from gerrychain.accept import always_accept\n",
    "from gerrychain.constraints import within_percent_of_ideal_population\n",
    "from gerrychain.proposals import recom\n",
    "from gerrychain.updaters import Tally, cut_edges"
   ],
   "id": "c8c170aaf9a896ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ],
   "id": "1e83a573685a6730"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This is a structured config with:\n",
    "\n",
    "Inputs:\n",
    "* `vtds_geo`: geospatial VTD parquet file with geometry and population column\n",
    "* `enacted_plan_map`: matching each VTD to enacted district ID\n",
    "\n",
    "Outputs:\n",
    "* `out_plan_map` : huge \"long\" table of `(plan_id, vtd_geoid, district_id)` for each sampled plan\n",
    "* `out_plans`: metadata per plan (seed, constraints, etc)\n",
    "\n",
    "Sampling Controls:\n",
    "* `epsilon`: allowed relative deviation from ideal district population\n",
    "* `n_steps`: total Markov steps\n",
    "* `burnin` : throw away initial steps\n",
    "* `thin` : keep every `thin`th step after burin\n",
    "* `seed`: RNG seed\n",
    "\n",
    "Column Naming\n",
    "* `vtd_id_col`, `enacted_vtd_control`, `enacted_dist_col`\n",
    "\n",
    "Operational:\n",
    "* `flush_every_plans` : periodic flushing to parquet\n",
    "* `ignore_geometry_errors` : last-resort option when building adjacency graph"
   ],
   "id": "bae1f8615c5c9bd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class RunConfig:\n",
    "    ensemble_id: str\n",
    "    vtds_geo: Path\n",
    "    enacted_plan_map: Path\n",
    "    out_plan_map: Path\n",
    "    out_plans: Path\n",
    "\n",
    "    pop_col: str\n",
    "    epsilon: float\n",
    "    n_steps: int\n",
    "    burnin: int\n",
    "    thin: int\n",
    "    seed: int\n",
    "\n",
    "    vtd_id_col: str\n",
    "    enacted_vtd_col: str\n",
    "    enacted_dist_col: str\n",
    "\n",
    "    flush_every_plans: int\n",
    "    ignore_geometry_errors: bool"
   ],
   "id": "f7cc25fcbb41563a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading and Validating the Enacted Assignment",
   "id": "db8b1e1aeac3880a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _read_enacted_map(path: Path, vtd_col: str, dist_col: str) -> pd.DataFrame:\n",
    "    # Reads the enacted mapping table\n",
    "    df = pd.read_parquet(path)\n",
    "    # Hard validation: must contain the VTD ID column you say it has.\n",
    "    if vtd_col not in df.columns:\n",
    "        raise ValueError(f\"enacted plan-map missing {vtd_col!r}. Columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Allows a common alias: if you asked for district_id but the file uses district, it adapts. Otherwise errors.\n",
    "    if dist_col not in df.columns:\n",
    "        if dist_col == \"district_id\" and \"district\" in df.columns:\n",
    "            dist_col = \"district\"\n",
    "        else:\n",
    "            raise ValueError(f\"enacted plan-map missing {dist_col!r}. Columns: {df.columns.tolist()}\")\n",
    "\n",
    "    out = df[[vtd_col, dist_col]].copy()\n",
    "    out = out.rename(columns={vtd_col: \"vtd_geoid\", dist_col: \"district_id\"})\n",
    "    # Normalizes column names to canonical \"vtd_geoid\" and \"district_id\" for downstream code\n",
    "    out[\"vtd_geoid\"] = out[\"vtd_geoid\"].astype(str)\n",
    "    out[\"district_id\"] = out[\"district_id\"].astype(str)\n",
    "    return out"
   ],
   "id": "37ab90e4d7c34ce9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creation of Output Directory",
   "id": "450130ffb39dbc18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _ensure_outputs(cfg: RunConfig) -> None:\n",
    "    cfg.out_plan_map.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cfg.out_plans.parent.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "c4c1a280fa60c8cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Streaming Parquet Writer for Plan-Map Rows\n",
    "* Defines schema explicitly.\n",
    "* Uses Zstandard compression.\n",
    "* Returns a writer you can append to repeatedly."
   ],
   "id": "e6a7b4903b89b42d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _make_planmap_writer(out_path: Path) -> pq.ParquetWriter:\n",
    "    schema = pa.schema(\n",
    "        [\n",
    "            (\"plan_id\", pa.string()),\n",
    "            (\"vtd_geoid\", pa.string()),\n",
    "            (\"district_id\", pa.string()),\n",
    "        ]\n",
    "    )\n",
    "    return pq.ParquetWriter(str(out_path), schema=schema, compression=\"zstd\")"
   ],
   "id": "1763eb7b7488b839"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Writes Buffered Triplets Into Parquet in Batches (Memory-Efficient)",
   "id": "d2b67f6f43a8cd68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _write_planmap_rows(writer: pq.ParquetWriter, rows: List[Tuple[str, str, str]]) -> None:\n",
    "    if not rows:\n",
    "        return\n",
    "    plan_ids, vtds, dists = zip(*rows)\n",
    "    writer.write_table(\n",
    "        pa.table(\n",
    "            {\n",
    "                \"plan_id\": pa.array(plan_ids, type=pa.string()),\n",
    "                \"vtd_geoid\": pa.array(vtds, type=pa.string()),\n",
    "                \"district_id\": pa.array(dists, type=pa.string()),\n",
    "            }\n",
    "        )\n",
    "    )"
   ],
   "id": "eeb329e83d4fe84d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Repair Geometries",
   "id": "53ebcc0cdd7e2ab9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _repair_geometries(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "\n",
    "    # Detects invalid polygons (self-intersections, ring issues, etc). Invalid geometry can break adjacency building.\n",
    "    invalid_mask = ~gdf.geometry.is_valid\n",
    "    n_bad = int(invalid_mask.sum())\n",
    "    if n_bad == 0:\n",
    "        return gdf\n",
    "\n",
    "    bad_ids = gdf.loc[invalid_mask].index.astype(str).tolist()[:10]\n",
    "    print(f\"[geom] found {n_bad} invalid geometries (examples: {bad_ids}). Repairing...\")\n",
    "\n",
    "    # Prefer make_valid() for newer GeoPandas/Shapely versions.\n",
    "    # Otherwise fallback to buffer(0) which often fixes self-intersections.\n",
    "    try:\n",
    "        gdf.loc[invalid_mask, \"geometry\"] = gdf.loc[invalid_mask].geometry.make_valid()\n",
    "    except Exception:\n",
    "        gdf.loc[invalid_mask, \"geometry\"] = gdf.loc[invalid_mask].geometry.buffer(0)\n",
    "\n",
    "    still_bad = int((~gdf.geometry.is_valid).sum())\n",
    "    if still_bad:\n",
    "        print(f\"[geom] WARNING: {still_bad} geometries still invalid after repair.\")\n",
    "    else:\n",
    "        print(\"[geom] repair complete: all geometries valid.\")\n",
    "    return gdf"
   ],
   "id": "f25a36f1c171f711"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_recom_ensemble(cfg: RunConfig) -> None:\n",
    "    # Ensures folders exist.\n",
    "    _ensure_outputs(cfg)\n",
    "    # Set RNG seed for reproducible proposals.\n",
    "    np.random.seed(cfg.seed)\n",
    "\n",
    "    # Loads the VTD polygons and attributes\n",
    "    gdf = gpd.read_parquet(cfg.vtds_geo)\n",
    "    # Validations\n",
    "    if cfg.vtd_id_col not in gdf.columns:\n",
    "        raise ValueError(f\"{cfg.vtds_geo} missing {cfg.vtd_id_col!r}. Columns: {gdf.columns.tolist()}\")\n",
    "    if \"geometry\" not in gdf.columns:\n",
    "        raise ValueError(f\"{cfg.vtds_geo} missing geometry column.\")\n",
    "    if cfg.pop_col not in gdf.columns:\n",
    "        raise ValueError(f\"{cfg.vtds_geo} missing pop col {cfg.pop_col!r}. Columns: {gdf.columns.tolist()}\")\n",
    "\n",
    "    gdf = gdf.copy()\n",
    "    # Type normalization\n",
    "    gdf[cfg.vtd_id_col] = gdf[cfg.vtd_id_col].astype(str)\n",
    "    # Population must be numeric; coercion errors are not silently ignored.\n",
    "    gdf[cfg.pop_col] = pd.to_numeric(gdf[cfg.pop_col], errors=\"raise\").astype(int)\n",
    "\n",
    "    # Set node IDs to the VTD geoids; this index becomes crucial for graph-building.\n",
    "    gdf = gdf.set_index(cfg.vtd_id_col, drop=False)\n",
    "\n",
    "    # Repairs invalid polygons before building adjacency.\n",
    "    gdf = _repair_geometries(gdf)\n",
    "\n",
    "    # Build adjacency graph.\n",
    "    if cfg.ignore_geometry_errors:\n",
    "        graph = Graph.from_geodataframe(gdf, ignore_errors=True)\n",
    "    else:\n",
    "        graph = Graph.from_geodataframe(gdf)\n",
    "\n",
    "    # Read enacted assignment\n",
    "    enacted = _read_enacted_map(cfg.enacted_plan_map, cfg.enacted_vtd_col, cfg.enacted_dist_col)\n",
    "    # Align with graph.\n",
    "    vtd_to_dist = enacted.set_index(\"vtd_geoid\")[\"district_id\"].to_dict()\n",
    "\n",
    "    # Guarantees every graph node has an enacted district label. Otherwise the initial partition can't be defined.\n",
    "    missing = [str(n) for n in graph.nodes if str(n) not in vtd_to_dist]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Enacted plan-map is missing {len(missing)} VTDs relative to the VTD geometry graph. \"\n",
    "            f\"Example missing: {missing[:10]}\"\n",
    "        )\n",
    "\n",
    "    # Creates the plan pi_0, the starting state of the Markov chain.\n",
    "    assignment: Dict[str, str] = {str(n): str(vtd_to_dist[str(n)]) for n in graph.nodes}\n",
    "\n",
    "    # Attach population to graph nodes (gerrychain reads node attributes).\n",
    "    pop_map = gdf[cfg.pop_col].astype(int).to_dict()\n",
    "    for n in graph.nodes:\n",
    "        graph.nodes[n][cfg.pop_col] = int(pop_map[str(n)])\n",
    "\n",
    "    updaters = {\"population\": Tally(cfg.pop_col, alias=\"population\"), \"cut_edges\": cut_edges}\n",
    "    init_part = GeographicPartition(graph, assignment=assignment, updaters=updaters)\n",
    "\n",
    "    districts = list(set(init_part.assignment.values()))\n",
    "    k = len(districts)\n",
    "    total_pop = sum(init_part[\"population\"].values())\n",
    "    ideal = total_pop / k\n",
    "\n",
    "    # -----------------------------\n",
    "    # IMPORTANT FIX:\n",
    "    # MarkovChain requires initial_state to satisfy constraints.\n",
    "    # If enacted plan violates epsilon under pop_col, auto-relax epsilon.\n",
    "    # -----------------------------\n",
    "    pops = list(init_part[\"population\"].values())\n",
    "    max_dev = max(abs(p - ideal) / ideal for p in pops)\n",
    "    eps = float(cfg.epsilon)\n",
    "    if max_dev > eps:\n",
    "        eps = float(max_dev) + 1e-6\n",
    "        print(\n",
    "            f\"[pop] enacted plan violates epsilon={cfg.epsilon:.6f} under pop_col={cfg.pop_col!r}. \"\n",
    "            f\"Max deviation is {max_dev:.6f}; relaxing epsilon to {eps:.6f} so the chain can start.\"\n",
    "        )\n",
    "\n",
    "    pop_constraint = within_percent_of_ideal_population(init_part, eps)\n",
    "\n",
    "    # -----------------------------\n",
    "    # IMPORTANT FIX:\n",
    "    # Your gerrychain version's recom expects (partition, ...) as first arg,\n",
    "    # so proposal must be a function(partition)->new_partition.\n",
    "    # -----------------------------\n",
    "    def proposal(partition):\n",
    "        return recom(\n",
    "            partition,\n",
    "            pop_col=cfg.pop_col,\n",
    "            pop_target=ideal,\n",
    "            epsilon=eps,\n",
    "            node_repeats=1,\n",
    "        )\n",
    "\n",
    "    chain = MarkovChain(\n",
    "        proposal=proposal,\n",
    "        constraints=[pop_constraint],\n",
    "        accept=always_accept,\n",
    "        initial_state=init_part,\n",
    "        total_steps=cfg.n_steps,\n",
    "    )\n",
    "\n",
    "    # Overwrite outputs\n",
    "    if cfg.out_plan_map.exists():\n",
    "        cfg.out_plan_map.unlink()\n",
    "    if cfg.out_plans.exists():\n",
    "        cfg.out_plans.unlink()\n",
    "\n",
    "    writer = _make_planmap_writer(cfg.out_plan_map)\n",
    "\n",
    "    kept = 0\n",
    "    buffer: List[Tuple[str, str, str]] = []\n",
    "    plans_meta: List[dict] = []\n",
    "\n",
    "    def keep(step: int) -> bool:\n",
    "        return step >= cfg.burnin and ((step - cfg.burnin) % cfg.thin) == 0\n",
    "\n",
    "    for step_idx, part in enumerate(chain):\n",
    "        if not keep(step_idx):\n",
    "            continue\n",
    "\n",
    "        kept += 1\n",
    "        plan_id = f\"{cfg.ensemble_id}_{kept:06d}\"\n",
    "\n",
    "        for vtd_geoid, dist in part.assignment.items():\n",
    "            buffer.append((plan_id, str(vtd_geoid), str(dist)))\n",
    "\n",
    "        plans_meta.append(\n",
    "            dict(\n",
    "                plan_id=plan_id,\n",
    "                plan_type=\"ENSEMBLE\",\n",
    "                cycle=None,\n",
    "                chamber=None,\n",
    "                ensemble_id=cfg.ensemble_id,\n",
    "                generator=\"recom\",\n",
    "                seed=int(cfg.seed),\n",
    "                constraints_json=json.dumps(\n",
    "                    {\n",
    "                        \"proposal\": \"recom\",\n",
    "                        \"epsilon_requested\": cfg.epsilon,\n",
    "                        \"epsilon_used\": eps,\n",
    "                        \"max_dev_enacted\": float(max_dev),\n",
    "                        \"ideal_pop\": float(ideal),\n",
    "                        \"n_districts\": int(k),\n",
    "                        \"burnin\": int(cfg.burnin),\n",
    "                        \"thin\": int(cfg.thin),\n",
    "                        \"n_steps\": int(cfg.n_steps),\n",
    "                        \"pop_col\": cfg.pop_col,\n",
    "                    }\n",
    "                ),\n",
    "                created_at=None,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if kept % cfg.flush_every_plans == 0:\n",
    "            _write_planmap_rows(writer, buffer)\n",
    "            buffer = []\n",
    "            print(f\"[ensemble] kept {kept} plans (flushed)\")\n",
    "\n",
    "    _write_planmap_rows(writer, buffer)\n",
    "    writer.close()\n",
    "\n",
    "    pd.DataFrame(plans_meta).to_parquet(cfg.out_plans, index=False)\n",
    "\n",
    "    print(f\"[ensemble] done. kept={kept}\")\n",
    "    print(f\"[ensemble] wrote plan-map: {cfg.out_plan_map}\")\n",
    "    print(f\"[ensemble] wrote plans meta: {cfg.out_plans}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    ap = argparse.ArgumentParser(description=\"Generate ReCom ensemble from processed geospatial VTDs\")\n",
    "\n",
    "    ap.add_argument(\"--vtds-geo\", required=True, help=\"Geospatial VTDs parquet with vtd_geoid+geometry+pop_col\")\n",
    "    ap.add_argument(\"--enacted-plan-map\", required=True, help=\"Enacted plan map parquet (vtd_geoid -> district_id)\")\n",
    "    ap.add_argument(\"--ensemble-id\", required=True)\n",
    "\n",
    "    ap.add_argument(\"--out-plan-map\", required=True, help=\"Output parquet plan-map for ensemble\")\n",
    "    ap.add_argument(\"--out-plans\", required=True, help=\"Output parquet plans metadata for ensemble\")\n",
    "\n",
    "    ap.add_argument(\"--pop-col\", default=\"vap_total\")\n",
    "    ap.add_argument(\"--epsilon\", type=float, default=0.01)\n",
    "    ap.add_argument(\"--n-steps\", type=int, default=5000)\n",
    "    ap.add_argument(\"--burnin\", type=int, default=500)\n",
    "    ap.add_argument(\"--thin\", type=int, default=10)\n",
    "    ap.add_argument(\"--seed\", type=int, default=20240101)\n",
    "\n",
    "    ap.add_argument(\"--vtd-id-col\", default=\"vtd_geoid\")\n",
    "    ap.add_argument(\"--enacted-vtd-col\", default=\"vtd_geoid\")\n",
    "    ap.add_argument(\"--enacted-dist-col\", default=\"district_id\")\n",
    "\n",
    "    ap.add_argument(\"--flush-every-plans\", type=int, default=25)\n",
    "    ap.add_argument(\n",
    "        \"--ignore-geometry-errors\",\n",
    "        action=\"store_true\",\n",
    "        help=\"If set, build graph with ignore_errors=True (last resort).\",\n",
    "    )\n",
    "\n",
    "    return ap"
   ],
   "id": "896077ee6c014f15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main() -> None:\n",
    "    args = build_parser().parse_args()\n",
    "\n",
    "    cfg = RunConfig(\n",
    "        ensemble_id=args.ensemble_id,\n",
    "        vtds_geo=Path(args.vtds_geo),\n",
    "        enacted_plan_map=Path(args.enacted_plan_map),\n",
    "        out_plan_map=Path(args.out_plan_map),\n",
    "        out_plans=Path(args.out_plans),\n",
    "        pop_col=args.pop_col,\n",
    "        epsilon=args.epsilon,\n",
    "        n_steps=args.n_steps,\n",
    "        burnin=args.burnin,\n",
    "        thin=args.thin,\n",
    "        seed=args.seed,\n",
    "        vtd_id_col=args.vtd_id_col,\n",
    "        enacted_vtd_col=args.enacted_vtd_col,\n",
    "        enacted_dist_col=args.enacted_dist_col,\n",
    "        flush_every_plans=args.flush_every_plans,\n",
    "        ignore_geometry_errors=args.ignore_geometry_errors,\n",
    "    )\n",
    "\n",
    "    generate_recom_ensemble(cfg)"
   ],
   "id": "c658810b2c65151c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "bc51425bf3855b54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
