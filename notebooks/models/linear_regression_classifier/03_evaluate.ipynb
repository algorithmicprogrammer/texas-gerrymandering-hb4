{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Needed Filepaths and Libraries",
   "id": "19205f2a04045e4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T03:02:47.565514Z",
     "start_time": "2025-10-11T03:02:46.592058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, balanced_accuracy_score,\n",
    "    f1_score, mean_squared_error, r2_score, classification_report\n",
    ")\n",
    "\n",
    "from texas_gerrymandering_hb4.config import IMAGES_DIR\n",
    "\n",
    "ART_DIR = Path(\"artifacts\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "COMPACTNESS_PCA_META = {}\n",
    "compactness_meta_path = ART_DIR / \"compactness_pca.json\"\n",
    "if compactness_meta_path.exists():\n",
    "    with compactness_meta_path.open() as f:\n",
    "        COMPACTNESS_PCA_META = json.load(f)\n",
    "    print(\"Loaded compactness PCA metadata for evaluation.\")\n",
    "else:\n",
    "    print(\"Warning: compactness_pca.json not found.\")\n"
   ],
   "id": "38573a9cd2340123",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-10-10 20:02:47.563\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mtexas_gerrymandering_hb4.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: /home/aimlexpert/Documents/GitHub/texas-gerrymandering-HB4\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded compactness PCA metadata for evaluation.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load in Test Split, Model, and Threshold",
   "id": "a1a081aca145372c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T03:02:47.678710Z",
     "start_time": "2025-10-11T03:02:47.572612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test = pd.read_parquet(ART_DIR / \"X_test.parquet\")\n",
    "y_test = pd.read_parquet(ART_DIR / \"y_test.parquet\")[\"party\"]\n",
    "\n",
    "pipeline = joblib.load(ART_DIR / \"active_model.pkl\")\n",
    "with open(ART_DIR / \"train_threshold.json\") as f:\n",
    "    thr_info = json.load(f)\n",
    "threshold = float(thr_info[\"threshold\"])\n",
    "variant = thr_info.get(\"variant\", \"unknown\")\n",
    "use_poly = thr_info.get(\"use_polynomial_features\")\n",
    "poly_degree = thr_info.get(\"polynomial_degree\")\n",
    "print(f\"Evaluating model variant: {variant} with threshold={threshold:.3f}\")\n",
    "if use_poly is not None:\n",
    "    print(f\"Polynomial features enabled: {use_poly} (degree={poly_degree})\")\n",
    "if COMPACTNESS_PCA_META:\n",
    "    print(\"Compactness PCA components:\", COMPACTNESS_PCA_META.get(\"pca_components\"))\n"
   ],
   "id": "75f9bc67e7e23250",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model variant: lasso with threshold=0.330\n",
      "Polynomial features enabled: False (degree=1)\n",
      "Compactness PCA components: [0.5326604170627146, 0.5420231196260704, 0.48495683113594357, 0.43278249712757744]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction and Classification",
   "id": "cd6b811478ebe2b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T03:02:47.688489Z",
     "start_time": "2025-10-11T03:02:47.683950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_score = pipeline.predict(X_test).clip(0, 1)\n",
    "y_pred  = (y_score >= threshold).astype(int)"
   ],
   "id": "5a353aaa7354d059",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Print Metrics and Save Report",
   "id": "da4d91580c8ed8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T03:02:47.736173Z",
     "start_time": "2025-10-11T03:02:47.732879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "bal = balanced_accuracy_score(y_test, y_pred)\n",
    "f1  = f1_score(y_test, y_pred, zero_division=0)\n",
    "mse = mean_squared_error(y_test, y_score)\n",
    "r2  = r2_score(y_test, y_score)\n",
    "cm  = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy          : {acc:.3f}\")\n",
    "print(f\"Balanced Accuracy : {bal:.3f}\")\n",
    "print(f\"F1 (Dem=1)        : {f1:.3f}\")\n",
    "print(f\"MSE               : {mse:.4f}\")\n",
    "print(f\"RÂ²               : {r2:.4f}\")\n",
    "print(\"Confusion Matrix:\n",
    "\", cm)\n",
    "\n",
    "with open(ART_DIR / \"metrics.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"variant\": variant,\n",
    "        \"threshold\": threshold,\n",
    "        \"accuracy\": acc,\n",
    "        \"balanced_accuracy\": bal,\n",
    "        \"f1\": f1,\n",
    "        \"mse\": mse,\n",
    "        \"r2\": r2,\n",
    "        \"use_polynomial_features\": use_poly,\n",
    "        \"polynomial_degree\": poly_degree,\n",
    "        \"compactness_pca\": COMPACTNESS_PCA_META,\n",
    "    }, f, indent=2)\n",
    "\n",
    "pd.DataFrame(classification_report(\n",
    "    y_test, y_pred, target_names=[\"Republican(0)\", \"Democrat(1)\"], output_dict=True, zero_division=0\n",
    ")).to_csv(ART_DIR / \"classification_report.csv\")\n"
   ],
   "id": "3f31a1684d78c611",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 14) (1702343232.py, line 14)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mprint(\"Confusion Matrix:\u001B[39m\n          ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m unterminated string literal (detected at line 14)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Confusion Matrix",
   "id": "fae949c8e63c29c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T03:02:47.797865538Z",
     "start_time": "2025-10-09T01:49:55.490471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_confusion_matrix(cm, path, labels=(\"Rep(0)\", \"Dem(1)\")):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(\"Confusion Matrix (Test)\")\n",
    "    plt.xticks([0, 1], labels)\n",
    "    plt.yticks([0, 1], labels)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "save_confusion_matrix(cm, IMAGES_DIR / \"confusion_matrix.png\")\n",
    "\n",
    "print(\"Evaluation complete. Saved metrics, report, and confusion matrix.\")"
   ],
   "id": "1033bc4028cd6a02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Saved metrics, report, and confusion matrix.\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
