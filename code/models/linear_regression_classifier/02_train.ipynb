{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Needed Libraries and Filepaths",
   "id": "ef6498b2a44d728b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:09.327093Z",
     "start_time": "2025-10-09T00:35:08.288928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from texas_gerrymandering_hb4.config import IMAGES_DIR\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "ART_DIR = Path(\"artifacts\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "e37881ca4f05c19e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-08 17:35:08.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtexas_gerrymandering_hb4.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/aimlexpert/Documents/GitHub/texas-gerrymandering-HB4\u001b[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data and Metadata",
   "id": "507a122c499ad34c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:09.352639Z",
     "start_time": "2025-10-09T00:35:09.334589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = pd.read_parquet(ART_DIR / \"X_train.parquet\")\n",
    "y_train = pd.read_parquet(ART_DIR / \"y_train.parquet\")[\"party\"]\n",
    "\n",
    "with open(ART_DIR / \"split_meta.json\") as f:\n",
    "    meta = json.load(f)\n",
    "NUMERIC = meta[\"numeric\"]\n",
    "CATEGORICAL = meta[\"categorical\"]"
   ],
   "id": "d74a12f075a3e0a1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:09.391275Z",
     "start_time": "2025-10-09T00:35:09.385537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Cell 3: Preprocessor ---\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"), CATEGORICAL),\n",
    "    (\"num\", StandardScaler(), NUMERIC),\n",
    "])\n",
    "\n",
    "# Helper to recover feature names after fit\n",
    "def get_feature_names(fitted_preprocessor):\n",
    "    ohe = fitted_preprocessor.named_transformers_[\"cat\"]\n",
    "    ohe_names = list(ohe.get_feature_names_out(CATEGORICAL))\n",
    "    feat_names = ohe_names + NUMERIC\n",
    "    return ohe_names, feat_names"
   ],
   "id": "264c2b5dddc57403",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tuning Threshold",
   "id": "e7ca019d521777b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:09.444709Z",
     "start_time": "2025-10-09T00:35:09.439369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pick_threshold(y_true, scores, metric=\"balanced_accuracy\"):\n",
    "    scores = np.asarray(scores)\n",
    "    grid = np.linspace(0.0, 1.0, 201)\n",
    "    best_thr, best_val = 0.5, -1.0\n",
    "    for thr in grid:\n",
    "        y_hat = (scores >= thr).astype(int)\n",
    "        val = balanced_accuracy_score(y_true, y_hat) if metric == \"balanced_accuracy\" else 0.0\n",
    "        if val > best_val:\n",
    "            best_val, best_thr = val, thr\n",
    "    return float(best_thr), float(best_val)"
   ],
   "id": "132927ed009cd6a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## K-Fold Cross Validation",
   "id": "8715c7ac8a81df0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:09.490958Z",
     "start_time": "2025-10-09T00:35:09.487641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Cell 5: Cross-val evaluator for regression-as-classifier ---\n",
    "def cv_bal_acc_for_reg_pipeline(pipeline, X, y, n_splits=5, random_state=42):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    scores = []\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        # fit on fold-train\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "        # tune threshold on fold-train ONLY\n",
    "        y_tr_score = pipeline.predict(X_tr).clip(0, 1)\n",
    "        thr, _ = pick_threshold(y_tr, y_tr_score, \"balanced_accuracy\")\n",
    "        # evaluate on fold-val\n",
    "        y_va_score = pipeline.predict(X_va).clip(0, 1)\n",
    "        y_va_pred = (y_va_score >= thr).astype(int)\n",
    "        bal = balanced_accuracy_score(y_va, y_va_pred)\n",
    "        scores.append(bal)\n",
    "    return float(np.mean(scores)), float(np.std(scores))"
   ],
   "id": "a768c91bb66746c7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Model Candidates",
   "id": "17f4702e2d715708"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:13.376558Z",
     "start_time": "2025-10-09T00:35:09.535409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alphas = np.logspace(-3, 3, 50)\n",
    "candidates = {\n",
    "    \"ols\": LinearRegression(),\n",
    "    \"ridge\": RidgeCV(alphas=alphas, cv=5, scoring=None),\n",
    "    \"lasso\": LassoCV(alphas=alphas, cv=5, max_iter=10000, n_jobs=-1),\n",
    "    \"elasticnet\": ElasticNetCV(l1_ratio=[0.2, 0.5, 0.8, 1.0], alphas=alphas, cv=5, max_iter=10000, n_jobs=-1)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_name, best_cv = None, -np.inf\n",
    "\n",
    "for name, reg in candidates.items():\n",
    "    pipe = Pipeline([(\"pre\", preprocessor), (\"reg\", reg)])\n",
    "    mean_bal, std_bal = cv_bal_acc_for_reg_pipeline(pipe, X_train, y_train, n_splits=5, random_state=42)\n",
    "    results[name] = {\"cv_balanced_accuracy_mean\": mean_bal, \"cv_balanced_accuracy_std\": std_bal}\n",
    "    print(f\"[CV] {name}: mean={mean_bal:.3f} \\u00b1 {std_bal:.3f}\")\n",
    "    if mean_bal > best_cv:\n",
    "        best_cv = mean_bal\n",
    "        best_name = name\n",
    "best_reg = candidates[best_name]\n",
    "print(f\"[SELECT] Best by CV balanced accuracy: {best_name} (mean={best_cv:.3f})\")"
   ],
   "id": "e0f16aca62944bbb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ols: mean=0.683 \u00b1 0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ridge: mean=0.850 \u00b1 0.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lasso: mean=0.850 \u00b1 0.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] elasticnet: mean=0.850 \u00b1 0.133\n",
      "[SELECT] Best by CV balanced accuracy: ridge (mean=0.850)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:13.748941Z",
     "start_time": "2025-10-09T00:35:13.449870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Cell 7: Fit best on full train & tune final threshold ---\n",
    "best_pipeline = Pipeline([(\"pre\", preprocessor), (\"reg\", best_reg)])\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "y_train_score = best_pipeline.predict(X_train).clip(0, 1)\n",
    "final_thr, bal_train = pick_threshold(y_train, y_train_score, \"balanced_accuracy\")\n",
    "print(f\"[TRAIN] Final threshold={final_thr:.3f}, balanced-acc(train)={bal_train:.3f}\")"
   ],
   "id": "f73fb6cb9dfad318",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Final threshold=0.350, balanced-acc(train)=0.917\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:13.889043Z",
     "start_time": "2025-10-09T00:35:13.769905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Cell 8: Save model, threshold, CV results, coefficients plot ---\n",
    "joblib.dump(best_pipeline, ART_DIR / \"active_model.pkl\")\n",
    "with open(ART_DIR / \"train_threshold.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\"variant\": best_name, \"threshold\": final_thr, \"balanced_accuracy_on_train\": bal_train},\n",
    "        f, indent=2\n",
    "    )\n",
    "with open(ART_DIR / \"cv_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# coefficients\n",
    "ohe_names, feat_names = get_feature_names(best_pipeline.named_steps[\"pre\"])\n",
    "coefs = best_pipeline.named_steps[\"reg\"].coef_\n",
    "coef_df = pd.DataFrame({\"feature\": feat_names, \"coef\": coefs}).sort_values(\n",
    "    \"coef\", key=lambda s: s.abs(), ascending=False\n",
    ")\n",
    "coef_df.to_csv(ART_DIR / \"linear_regression_coefficients_active.csv\", index=False)\n",
    "\n",
    "plt.figure()\n",
    "plt.barh(coef_df[\"feature\"], coef_df[\"coef\"])\n",
    "plt.title(f\"Linear Regression Coefficients ({best_name})\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR / \"linear_regression_coefficients_active.png\", dpi=200)\n",
    "plt.close()"
   ],
   "id": "861ba0ce8b646f5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Diagnostics",
   "id": "507b77b8c24fc444"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:14.366325Z",
     "start_time": "2025-10-09T00:35:13.894523Z"
    }
   },
   "cell_type": "code",
   "source": "# Fit a separate OLS baseline for diagnostics only\nols_pipe = Pipeline([(\"pre\", preprocessor), (\"reg\", LinearRegression())])\nols_pipe.fit(X_train, y_train)\nX_design = ols_pipe.named_steps[\"pre\"].transform(X_train)  # dense array\nohe_names_diag = list(ols_pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].get_feature_names_out(CATEGORICAL))\nfeat_names_diag = ohe_names_diag + NUMERIC\n\n# statsmodels OLS\nX_sm_df = pd.DataFrame(X_design, columns=feat_names_diag)\nX_sm_df = sm.add_constant(X_sm_df)\nols_sm = sm.OLS(y_train.values, X_sm_df).fit()\n\nsummary_text = ols_sm.summary().as_text()\nprint(summary_text)\n\nfig = plt.figure(figsize=(12, 8))\nplt.axis(\"off\")\nplt.text(0.0, 1.0, summary_text, fontsize=8, fontfamily=\"monospace\", va=\"top\")\nplt.tight_layout()\nfig.savefig(IMAGES_DIR / \"ols_summary.png\", dpi=200)\nplt.close(fig)\n\npvalues_df = (\n    pd.Series(ols_sm.pvalues, index=ols_sm.model.exog_names, name=\"p_value\")\n    .reset_index()\n    .rename(columns={\"index\": \"term\"})\n)\nprint(pvalues_df)\n\nfig, ax = plt.subplots(figsize=(8, max(2, 0.3 * len(pvalues_df))))\nax.axis(\"off\")\ntable = ax.table(\n    cellText=[[row.term, f\"{row.p_value:.4g}\"] for row in pvalues_df.itertuples()],\n    colLabels=[\"Term\", \"p-value\"],\n    loc=\"center\",\n    cellLoc=\"left\",\n)\ntable.auto_set_font_size(False)\ntable.set_fontsize(8)\ntable.scale(1, 1.4)\nfig.tight_layout()\nfig.savefig(IMAGES_DIR / \"ols_pvalues.png\", dpi=200)\nplt.close(fig)\n\n# VIF\nvif_rows = []\nX_sm_values = X_sm_df.values\nfor i in range(1, X_sm_values.shape[1]):  # skip intercept\n    vif_rows.append((feat_names_diag[i-1], float(variance_inflation_factor(X_sm_values[:, 1:], i-1))))\nvif_df = pd.DataFrame(vif_rows, columns=[\"feature\", \"VIF\"]).sort_values(\"VIF\", ascending=False)\nvif_df.to_csv(ART_DIR / \"vif_ols.csv\", index=False)\n\nplt.figure()\nplt.barh(vif_df[\"feature\"], vif_df[\"VIF\"])\nplt.title(\"VIF (OLS baseline, Train)\")\nplt.xlabel(\"VIF\")\nplt.tight_layout()\nplt.savefig(IMAGES_DIR / \"vif_ols.png\", dpi=200)\nplt.close()\n\n# residuals & QQ\ny_fit = ols_pipe.predict(X_train)\nresid = y_train.values - y_fit\n\nplt.figure(); plt.scatter(y_fit, resid); plt.axhline(0, ls=\"--\")\nplt.title(\"Residuals vs Fitted (OLS baseline)\")\nplt.xlabel(\"Fitted\"); plt.ylabel(\"Residual\"); plt.tight_layout()\nplt.savefig(IMAGES_DIR / \"residuals_vs_fitted_ols.png\", dpi=200); plt.close()\n\nplt.figure(); plt.hist(resid, bins=12); plt.title(\"Residuals Histogram (OLS baseline)\")\nplt.tight_layout(); plt.savefig(IMAGES_DIR / \"residuals_hist_ols.png\", dpi=200); plt.close()\n\nfig = sm.qqplot(resid, line='45', fit=True); plt.title(\"QQ Plot (OLS baseline)\")\nplt.tight_layout(); fig.savefig(IMAGES_DIR / \"qqplot_residuals_ols.png\", dpi=200); plt.close()\n\n# Influence / Cook's D\ninfluence = ols_sm.get_influence()\ncooks_d = influence.cooks_distance[0]\nleverage = influence.hat_matrix_diag\ninfl_df = pd.DataFrame({\"index\": X_train.index, \"cooks_d\": cooks_d, \"leverage\": leverage, \"residual\": resid}).set_index(\"index\")\ninfl_df.sort_values(\"cooks_d\", ascending=False).to_csv(ART_DIR / \"influence_ols.csv\")\n\nplt.figure(); plt.scatter(leverage, resid)\nplt.title(\"Leverage vs Residuals (OLS baseline)\")\nplt.xlabel(\"Leverage\"); plt.ylabel(\"Residual\"); plt.tight_layout()\nplt.savefig(IMAGES_DIR / \"leverage_vs_residuals_ols.png\", dpi=200); plt.close()\n",
   "id": "77132463d7ab9f09",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save Metadata",
   "id": "14082f8461224489"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T00:35:14.374547Z",
     "start_time": "2025-10-09T00:35:14.371946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(ART_DIR / \"training_summary.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"selected_variant\": best_name,\n",
    "        \"train_balanced_accuracy\": bal_train,\n",
    "        \"final_threshold\": final_thr,\n",
    "        \"cv_results\": results\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Training complete. Saved active_model.pkl, threshold, CV results, coefficients, and diagnostics.\")"
   ],
   "id": "1b28cdf370933820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Saved active_model.pkl, threshold, CV results, coefficients, and diagnostics.\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}