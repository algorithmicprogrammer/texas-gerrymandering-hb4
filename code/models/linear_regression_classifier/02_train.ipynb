{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## Import Needed Libraries and Filepaths", "id": "ef6498b2a44d728b"}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:40.178100Z", "start_time": "2025-10-09T01:47:40.173424Z"}}, "cell_type": "code", "source": ["import json\n", "import joblib\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "from pathlib import Path\n", "\n", "from texas_gerrymandering_hb4.config import IMAGES_DIR\n", "\n", "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, SplineTransformer\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n", "from sklearn.model_selection import KFold\n", "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n", "from sklearn.base import clone\n", "\n", "import statsmodels.api as sm\n", "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"], "id": "e37881ca4f05c19e", "outputs": [], "execution_count": 20}, {"metadata": {}, "cell_type": "markdown", "source": "## Load Data and Metadata", "id": "507a122c499ad34c"}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:40.189969Z", "start_time": "2025-10-09T01:47:40.182895Z"}}, "cell_type": "code", "source": ["X_train = pd.read_parquet(ART_DIR / \"X_train.parquet\")\n", "y_train = pd.read_parquet(ART_DIR / \"y_train.parquet\")[\"party\"]\n", "\n", "with open(ART_DIR / \"split_meta.json\") as f:\n", "    meta = json.load(f)\n", "NUMERIC = meta[\"numeric\"]\n", "CATEGORICAL = meta[\"categorical\"]\n", "COMPACTNESS_PCA_META = meta.get(\"compactness_pca\", {})\n", "if COMPACTNESS_PCA_META:\n", "    print(\"Loaded compactness PCA metadata:\")\n", "    print(json.dumps(COMPACTNESS_PCA_META, indent=2))\n", "else:\n", "    print(\"No compactness PCA metadata found in split_meta.json\")\n"], "id": "d74a12f075a3e0a1", "outputs": [], "execution_count": 21}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:40.235769Z", "start_time": "2025-10-09T01:47:40.231562Z"}}, "cell_type": "code", "source": ["# --- Cell 3: Preprocessor ---\n", "POLY_DEGREES = [2, 3]\n", "SPLINE_CONFIGS = [\n", "    {\"degree\": 3, \"n_knots\": 5, \"include_bias\": False, \"extrapolation\": \"linear\"},\n", "    {\"degree\": 3, \"n_knots\": 7, \"include_bias\": False, \"extrapolation\": \"linear\"},\n", "]\n", "\n", "LINEAR_FEATURE_SPEC = {\"kind\": \"linear\"}\n", "\n", "\n", "def make_preprocessor(feature_engineering=None):\n", "    feature_engineering = feature_engineering or LINEAR_FEATURE_SPEC\n", "    kind = feature_engineering.get(\"kind\", \"linear\")\n", "    numeric_steps = []\n", "\n", "    if kind == \"poly\":\n", "        degree = int(feature_engineering.get(\"degree\", 2))\n", "        include_bias = bool(feature_engineering.get(\"include_bias\", False))\n", "        numeric_steps.extend([\n", "            (\"scale_in\", StandardScaler()),\n", "            (\"poly\", PolynomialFeatures(degree=degree, include_bias=include_bias)),\n", "            (\"scale_out\", StandardScaler()),\n", "        ])\n", "    elif kind == \"spline\":\n", "        degree = int(feature_engineering.get(\"degree\", 3))\n", "        n_knots = int(feature_engineering.get(\"n_knots\", degree + 2))\n", "        include_bias = bool(feature_engineering.get(\"include_bias\", False))\n", "        extrapolation = feature_engineering.get(\"extrapolation\", \"linear\")\n", "        numeric_steps.extend([\n", "            (\"scale_in\", StandardScaler()),\n", "            (\n", "                \"spline\",\n", "                SplineTransformer(\n", "                    degree=degree,\n", "                    n_knots=n_knots,\n", "                    include_bias=include_bias,\n", "                    extrapolation=extrapolation,\n", "                ),\n", "            ),\n", "            (\"scale_out\", StandardScaler()),\n", "        ])\n", "    else:\n", "        numeric_steps.append((\"scale\", StandardScaler()))\n", "\n", "    numeric_transformer = Pipeline(numeric_steps)\n", "    return ColumnTransformer([\n", "        (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"), CATEGORICAL),\n", "        (\"num\", numeric_transformer, NUMERIC),\n", "    ])\n", "\n", "\n", "# Helper to recover feature names after fit\n", "def get_feature_names(fitted_preprocessor):\n", "    ohe = fitted_preprocessor.named_transformers_[\"cat\"]\n", "    ohe_names = list(ohe.get_feature_names_out(CATEGORICAL))\n", "    num_transformer = fitted_preprocessor.named_transformers_[\"num\"]\n", "    num_names = list(NUMERIC)\n", "    if hasattr(num_transformer, \"named_steps\"):\n", "        steps = num_transformer.named_steps\n", "        if \"poly\" in steps:\n", "            num_names = list(steps[\"poly\"].get_feature_names_out(NUMERIC))\n", "        elif \"spline\" in steps:\n", "            num_names = list(steps[\"spline\"].get_feature_names_out(NUMERIC))\n", "    return ohe_names, ohe_names + num_names\n"], "id": "264c2b5dddc57403", "outputs": [], "execution_count": 22}, {"metadata": {}, "cell_type": "markdown", "source": "## Tuning Threshold", "id": "e7ca019d521777b1"}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:40.287989Z", "start_time": "2025-10-09T01:47:40.282368Z"}}, "cell_type": "code", "source": ["def pick_threshold(y_true, scores, metric=\"balanced_accuracy\"):\n", "    scores = np.asarray(scores)\n", "    grid = np.linspace(0.0, 1.0, 201)\n", "    best_thr, best_val = 0.5, -1.0\n", "    for thr in grid:\n", "        y_hat = (scores >= thr).astype(int)\n", "        val = balanced_accuracy_score(y_true, y_hat) if metric == \"balanced_accuracy\" else 0.0\n", "        if val > best_val:\n", "            best_val, best_thr = val, thr\n", "    return float(best_thr), float(best_val)"], "id": "132927ed009cd6a", "outputs": [], "execution_count": 23}, {"metadata": {}, "cell_type": "markdown", "source": "## K-Fold Cross Validation", "id": "8715c7ac8a81df0e"}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:40.341498Z", "start_time": "2025-10-09T01:47:40.334995Z"}}, "cell_type": "code", "source": ["# --- Cell 5: Cross-val evaluator for regression-as-classifier ---\n", "def cv_bal_acc_for_reg_pipeline(pipeline, X, y, n_splits=5, random_state=42):\n", "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n", "    scores = []\n", "    for tr_idx, va_idx in kf.split(X):\n", "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n", "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n", "        # fit on fold-train\n", "        pipeline.fit(X_tr, y_tr)\n", "        # tune threshold on fold-train ONLY\n", "        y_tr_score = pipeline.predict(X_tr).clip(0, 1)\n", "        thr, _ = pick_threshold(y_tr, y_tr_score, \"balanced_accuracy\")\n", "        # evaluate on fold-val\n", "        y_va_score = pipeline.predict(X_va).clip(0, 1)\n", "        y_va_pred = (y_va_score >= thr).astype(int)\n", "        bal = balanced_accuracy_score(y_va, y_va_pred)\n", "        scores.append(bal)\n", "    return float(np.mean(scores)), float(np.std(scores))"], "id": "a768c91bb66746c7", "outputs": [], "execution_count": 24}, {"metadata": {}, "cell_type": "markdown", "source": "## Define Model Candidates", "id": "17f4702e2d715708"}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:44.342141Z", "start_time": "2025-10-09T01:47:40.391093Z"}}, "cell_type": "code", "source": ["alphas = np.logspace(-3, 3, 50)\n", "regressors = {\n", "    \"ols\": LinearRegression(),\n", "    \"ridge\": RidgeCV(alphas=alphas, cv=5, scoring=None),\n", "    \"lasso\": LassoCV(alphas=alphas, cv=5, max_iter=10000, n_jobs=-1),\n", "    \"elasticnet\": ElasticNetCV(l1_ratio=[0.2, 0.5, 0.8, 1.0], alphas=alphas, cv=5, max_iter=10000, n_jobs=-1),\n", "}\n", "\n", "feature_variants = [\n", "    (\"linear\", {\"kind\": \"linear\"}),\n", "]\n", "feature_variants.extend((f\"poly_deg{deg}\", {\"kind\": \"poly\", \"degree\": deg, \"include_bias\": False}) for deg in POLY_DEGREES)\n", "feature_variants.extend(\n", "    (\n", "        f\"spline_knots{cfg['n_knots']}\",\n", "        {\"kind\": \"spline\", **cfg},\n", "    )\n", "    for cfg in SPLINE_CONFIGS\n", ")\n", "\n", "candidate_specs = {}\n", "for feat_name, feat_cfg in feature_variants:\n", "    for reg_name, reg in regressors.items():\n", "        suffix = \"\" if feat_name == \"linear\" else f\"_{feat_name}\"\n", "        key = f\"{reg_name}{suffix}\"\n", "        candidate_specs[key] = {\n", "            \"reg\": reg,\n", "            \"feature_engineering\": dict(feat_cfg),\n", "        }\n", "\n", "results = {}\n", "best_name, best_cv = None, -np.inf\n", "best_feature_engineering = dict(LINEAR_FEATURE_SPEC)\n", "\n", "for name, spec in candidate_specs.items():\n", "    reg = clone(spec[\"reg\"])\n", "    feature_engineering = dict(spec.get(\"feature_engineering\", LINEAR_FEATURE_SPEC))\n", "    preprocessor = make_preprocessor(feature_engineering)\n", "    pipe = Pipeline([(\"pre\", preprocessor), (\"reg\", reg)])\n", "    mean_bal, std_bal = cv_bal_acc_for_reg_pipeline(pipe, X_train, y_train, n_splits=5, random_state=42)\n", "    use_poly = feature_engineering.get(\"kind\") == \"poly\"\n", "    poly_degree = feature_engineering.get(\"degree\", 1) if use_poly else 1\n", "    results[name] = {\n", "        \"cv_balanced_accuracy_mean\": mean_bal,\n", "        \"cv_balanced_accuracy_std\": std_bal,\n", "        \"use_polynomial_features\": use_poly,\n", "        \"polynomial_degree\": poly_degree if use_poly else 1,\n", "        \"feature_engineering\": feature_engineering,\n", "    }\n", "    tag = feature_engineering.get(\"kind\", \"linear\")\n", "    print(f\"[CV] {name} ({tag}): mean={mean_bal:.3f} \u00b1 {std_bal:.3f}\")\n", "    if mean_bal > best_cv:\n", "        best_cv = mean_bal\n", "        best_name = name\n", "        best_feature_engineering = dict(feature_engineering)\n", "\n", "best_spec = candidate_specs[best_name]\n", "best_reg = clone(best_spec[\"reg\"])\n", "print(f\"[SELECT] Best by CV balanced accuracy: {best_name} (mean={best_cv:.3f}, features={best_feature_engineering})\")\n"], "id": "e0f16aca62944bbb", "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n", "  warnings.warn(\"y_pred contains classes not in y_true\")\n", "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n", "  warnings.warn(\"y_pred contains classes not in y_true\")\n"]}, {"name": "stdout", "output_type": "stream", "text": ["[CV] ols: mean=0.683 \u00b1 0.122\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n", "  warnings.warn(\n", "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n", "  warnings.warn(\"y_pred contains classes not in y_true\")\n"]}, {"name": "stdout", "output_type": "stream", "text": ["[CV] ridge: mean=0.850 \u00b1 0.133\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n", "  warnings.warn(\n", "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n", "  warnings.warn(\"y_pred contains classes not in y_true\")\n"]}, {"name": "stdout", "output_type": "stream", "text": ["[CV] lasso: mean=0.850 \u00b1 0.133\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n", "  warnings.warn(\n", "/home/aimlexpert/~/venvs/arrow/bin/python /lib/python3.12/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n", "  warnings.warn(\"y_pred contains classes not in y_true\")\n"]}, {"name": "stdout", "output_type": "stream", "text": ["[CV] elasticnet: mean=0.850 \u00b1 0.133\n", "[SELECT] Best by CV balanced accuracy: ridge (mean=0.850)\n"]}], "execution_count": 25}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:44.698418Z", "start_time": "2025-10-09T01:47:44.401118Z"}}, "cell_type": "code", "source": ["# --- Cell 7: Fit best on full train & tune final threshold ---\n", "best_pipeline = Pipeline([(\"pre\", make_preprocessor(best_feature_engineering)), (\"reg\", best_reg)])\n", "best_pipeline.fit(X_train, y_train)\n", "y_train_score = best_pipeline.predict(X_train).clip(0, 1)\n", "final_thr, bal_train = pick_threshold(y_train, y_train_score, \"balanced_accuracy\")\n", "print(f\"[TRAIN] Final threshold={final_thr:.3f}, balanced-acc(train)={bal_train:.3f}\")\n"], "id": "f73fb6cb9dfad318", "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[TRAIN] Final threshold=0.350, balanced-acc(train)=0.917\n"]}], "execution_count": 26}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:44.813074Z", "start_time": "2025-10-09T01:47:44.707333Z"}}, "cell_type": "code", "source": ["# --- Cell 8: Save model, threshold, CV results, coefficients plot ---\n", "joblib.dump(best_pipeline, ART_DIR / \"active_model.pkl\")\n", "with open(ART_DIR / \"train_threshold.json\", \"w\") as f:\n", "    json.dump(\n", "        {\n", "            \"variant\": best_name,\n", "            \"threshold\": final_thr,\n", "            \"balanced_accuracy_on_train\": bal_train,\n", "            \"use_polynomial_features\": best_feature_engineering.get(\"kind\") == \"poly\",\n", "            \"polynomial_degree\": best_feature_engineering.get(\"degree\", 1) if best_feature_engineering.get(\"kind\") == \"poly\" else 1,\n", "            \"feature_engineering\": best_feature_engineering,\n", "        },\n", "        f, indent=2\n", "    )\n", "with open(ART_DIR / \"cv_results.json\", \"w\") as f:\n", "    json.dump(results, f, indent=2)\n", "\n", "# coefficients\n", "ohe_names, feat_names = get_feature_names(best_pipeline.named_steps[\"pre\"])\n", "coefs = best_pipeline.named_steps[\"reg\"].coef_\n", "coef_df = pd.DataFrame({\"feature\": feat_names, \"coef\": coefs}).sort_values(\n", "    \"coef\", key=lambda s: s.abs(), ascending=False\n", ")\n", "coef_df.to_csv(ART_DIR / \"linear_regression_coefficients_active.csv\", index=False)\n", "\n", "plt.figure()\n", "plt.barh(coef_df[\"feature\"], coef_df[\"coef\"])\n", "plt.title(f\"Linear Regression Coefficients ({best_name})\")\n", "plt.xlabel(\"Coefficient Value\")\n", "plt.tight_layout()\n", "plt.savefig(IMAGES_DIR / \"linear_regression_coefficients_active.png\", dpi=200)\n", "plt.close()\n"], "id": "861ba0ce8b646f5", "outputs": [], "execution_count": 27}, {"metadata": {}, "cell_type": "markdown", "source": "## Model Diagnostics", "id": "507b77b8c24fc444"}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:45.517701Z", "start_time": "2025-10-09T01:47:44.817206Z"}}, "cell_type": "code", "source": ["# Fit a separate OLS baseline for diagnostics only\n", "diagnostic_preprocessor = make_preprocessor(best_feature_engineering)\n", "ols_pipe = Pipeline([(\"pre\", diagnostic_preprocessor), (\"reg\", LinearRegression())])\n", "ols_pipe.fit(X_train, y_train)\n", "X_design = ols_pipe.named_steps[\"pre\"].transform(X_train)  # dense array\n", "ohe_names_diag, feat_names_diag = get_feature_names(ols_pipe.named_steps[\"pre\"])\n", "\n", "# statsmodels OLS\n", "X_sm_df = pd.DataFrame(X_design, columns=feat_names_diag)\n", "X_sm_df = sm.add_constant(X_sm_df)\n", "ols_sm = sm.OLS(y_train.values, X_sm_df).fit()\n", "\n", "summary_text = ols_sm.summary().as_text()\n", "print(summary_text)\n", "\n", "fig = plt.figure(figsize=(12, 8))\n", "plt.axis(\"off\")\n", "plt.text(0.0, 1.0, summary_text, fontsize=8, fontfamily=\"monospace\", va=\"top\")\n", "plt.tight_layout()\n", "fig.savefig(IMAGES_DIR / \"ols_summary.png\", dpi=200)\n", "plt.close(fig)\n", "\n", "pvalues_df = (\n", "    pd.Series(ols_sm.pvalues, index=ols_sm.model.exog_names, name=\"p_value\")\n", "    .reset_index()\n", "    .rename(columns={\"index\": \"term\"})\n", ")\n", "print(pvalues_df)\n", "\n", "fig, ax = plt.subplots(figsize=(8, max(2, 0.3 * len(pvalues_df))))\n", "ax.axis(\"off\")\n", "table = ax.table(\n", "    cellText=[[row.term, f\"{row.p_value:.4g}\"] for row in pvalues_df.itertuples()],\n", "    colLabels=[\"Term\", \"p-value\"],\n", "    loc=\"center\",\n", "    cellLoc=\"left\",\n", ")\n", "table.auto_set_font_size(False)\n", "table.set_fontsize(8)\n", "table.scale(1, 1.4)\n", "fig.tight_layout()\n", "fig.savefig(IMAGES_DIR / \"ols_pvalues.png\", dpi=200)\n", "plt.close(fig)\n", "\n", "# VIF\n", "vif_rows = []\n", "X_sm_values = X_sm_df.values\n", "for i in range(1, X_sm_values.shape[1]):  # skip intercept\n", "    vif_rows.append((feat_names_diag[i-1], float(variance_inflation_factor(X_sm_values[:, 1:], i-1))))\n", "vif_df = pd.DataFrame(vif_rows, columns=[\"feature\", \"VIF\"]).sort_values(\"VIF\", ascending=False)\n", "vif_df.to_csv(ART_DIR / \"vif_ols.csv\", index=False)\n", "\n", "plt.figure()\n", "plt.barh(vif_df[\"feature\"], vif_df[\"VIF\"])\n", "plt.title(\"VIF (diagnostic OLS, Train)\")\n", "plt.xlabel(\"VIF\")\n", "plt.tight_layout()\n", "plt.savefig(IMAGES_DIR / \"vif_ols.png\", dpi=200)\n", "plt.close()\n", "\n", "# residuals & QQ\n", "y_fit = ols_pipe.predict(X_train)\n", "resid = y_train.values - y_fit\n", "\n", "plt.figure(); plt.scatter(y_fit, resid); plt.axhline(0, ls=\"--\")\n", "plt.title(\"Residuals vs Fitted (diagnostic OLS)\")\n", "plt.xlabel(\"Fitted\"); plt.ylabel(\"Residual\"); plt.tight_layout()\n", "plt.savefig(IMAGES_DIR / \"residuals_vs_fitted_ols.png\", dpi=200); plt.close()\n", "\n", "plt.figure(); plt.hist(resid, bins=12); plt.title(\"Residuals Histogram (diagnostic OLS)\")\n", "plt.tight_layout(); plt.savefig(IMAGES_DIR / \"residuals_hist_ols.png\", dpi=200); plt.close()\n", "\n", "fig = sm.qqplot(resid, line='45', fit=True); plt.title(\"QQ Plot (diagnostic OLS)\")\n", "plt.tight_layout(); fig.savefig(IMAGES_DIR / \"qqplot_residuals_ols.png\", dpi=200); plt.close()\n", "\n", "# Influence / Cook's D\n", "influence = ols_sm.get_influence()\n", "cooks_d = influence.cooks_distance[0]\n", "leverage = influence.hat_matrix_diag\n", "infl_df = pd.DataFrame({\"index\": X_train.index, \"cooks_d\": cooks_d, \"leverage\": leverage, \"residual\": resid}).set_index(\"index\")\n", "infl_df.sort_values(\"cooks_d\", ascending=False).to_csv(ART_DIR / \"influence_ols.csv\")\n", "\n", "plt.figure(); plt.scatter(leverage, resid)\n", "plt.title(\"Leverage vs Residuals (diagnostic OLS)\")\n", "plt.xlabel(\"Leverage\"); plt.ylabel(\"Residual\"); plt.tight_layout()\n", "plt.savefig(IMAGES_DIR / \"leverage_vs_residuals_ols.png\", dpi=200); plt.close()\n"], "id": "77132463d7ab9f09", "outputs": [{"name": "stdout", "output_type": "stream", "text": ["                            OLS Regression Results                            \n", "==============================================================================\n", "Dep. Variable:                      y   R-squared:                       0.677\n", "Model:                            OLS   Adj. R-squared:                  0.516\n", "Method:                 Least Squares   F-statistic:                     4.194\n", "Date:                Wed, 08 Oct 2025   Prob (F-statistic):            0.00469\n", "Time:                        18:47:44   Log-Likelihood:                 1.0381\n", "No. Observations:                  28   AIC:                             17.92\n", "Df Residuals:                      18   BIC:                             31.25\n", "Df Model:                           9                                         \n", "Covariance Type:            nonrobust                                         \n", "==============================================================================================\n", "                                 coef    std err          t      P>|t|      [0.025      0.975]\n", "----------------------------------------------------------------------------------------------\n", "const                         -0.0462      0.531     -0.087      0.932      -1.162       1.069\n", "majority_race_pct_hispanic     0.2437      0.531      0.459      0.652      -0.872       1.360\n", "majority_race_pct_white        0.2916      0.601      0.485      0.634      -0.972       1.555\n", "polsby_popper                  0.0738      0.542      0.136      0.893      -1.064       1.212\n", "schwartzberg                  -0.0472      0.619     -0.076      0.940      -1.348       1.253\n", "convex_hull_ratio             -0.0904      0.117     -0.774      0.449      -0.336       0.155\n", "reock                          0.0851      0.082      1.037      0.313      -0.087       0.257\n", "pct_black                      0.3582      0.150      2.391      0.028       0.043       0.673\n", "pct_asian                      0.1779      0.074      2.404      0.027       0.022       0.333\n", "pct_hispanic                   0.2374      0.155      1.528      0.144      -0.089       0.564\n", "==============================================================================\n", "Omnibus:                       12.499   Durbin-Watson:                   2.090\n", "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               12.661\n", "Skew:                           1.174   Prob(JB):                      0.00178\n", "Kurtosis:                       5.311   Cond. No.                         33.2\n", "==============================================================================\n", "\n", "Notes:\n", "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n", "                         term   p_value\n", "0                       const  0.931590\n", "1  majority_race_pct_hispanic  0.651944\n", "2     majority_race_pct_white  0.633560\n", "3               polsby_popper  0.893092\n", "4                schwartzberg  0.940052\n", "5           convex_hull_ratio  0.449214\n", "6                       reock  0.313415\n", "7                   pct_black  0.027925\n", "8                   pct_asian  0.027218\n", "9                pct_hispanic  0.143876\n"]}], "execution_count": 28}, {"metadata": {}, "cell_type": "markdown", "source": "## Save Metadata", "id": "14082f8461224489"}, {"metadata": {"ExecuteTime": {"end_time": "2025-10-09T01:47:45.525263Z", "start_time": "2025-10-09T01:47:45.522867Z"}}, "cell_type": "code", "source": ["with open(ART_DIR / \"training_summary.json\", \"w\") as f:\n", "    json.dump({\n", "        \"selected_variant\": best_name,\n", "        \"train_balanced_accuracy\": bal_train,\n", "        \"final_threshold\": final_thr,\n", "        \"cv_results\": results,\n", "        \"compactness_pca\": COMPACTNESS_PCA_META,\n", "        \"feature_engineering\": best_feature_engineering,\n", "        \"use_polynomial_features\": best_feature_engineering.get(\"kind\") == \"poly\",\n", "        \"polynomial_degree\": best_feature_engineering.get(\"degree\", 1) if best_feature_engineering.get(\"kind\") == \"poly\" else 1,\n", "    }, f, indent=2)\n", "\n", "print(\"Training complete. Saved active_model.pkl, threshold, CV results, coefficients, and diagnostics.\")\n"], "id": "1b28cdf370933820", "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training complete. Saved active_model.pkl, threshold, CV results, coefficients, and diagnostics.\n"]}], "execution_count": 29}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.6"}}, "nbformat": 4, "nbformat_minor": 5}