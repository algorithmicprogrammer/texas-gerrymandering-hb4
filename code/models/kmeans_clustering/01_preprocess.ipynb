{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T01:15:17.590245Z",
     "start_time": "2025-09-25T01:15:17.587817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ART_DIR  = \"artifacts\"               # output dir\n",
    "RACE_COLS = [\"pct_white\", \"pct_black\", \"pct_asian\", \"pct_hispanic\"]\n",
    "ID_COL = \"district_id\""
   ],
   "id": "15ed5ea9ffe8d6a4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T01:15:18.309587Z",
     "start_time": "2025-09-25T01:15:17.652975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from texas_gerrymandering_hb4.config import FINAL_CSV, RACE\n",
    "\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(FINAL_CSV)\n",
    "df.shape, df.head()"
   ],
   "id": "b31921d0454b9ea1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-09-24 18:15:18.300\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mtexas_gerrymandering_hb4.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: /home/aimlexpert/Documents/GitHub/texas-gerrymandering-HB4\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((38, 11),\n",
       "    district_id  polsby_popper  schwartzberg  convex_hull_ratio     reock  \\\n",
       " 0            1       0.193575      0.439971           0.722970  0.407570   \n",
       " 1            2       0.165232      0.406487           0.625270  0.417351   \n",
       " 2            3       0.216761      0.465576           0.805445  0.273916   \n",
       " 3            4       0.103462      0.321654           0.574190  0.222752   \n",
       " 4            5       0.184465      0.429494           0.823171  0.310183   \n",
       " \n",
       "    pct_white  pct_black  pct_asian  pct_hispanic  dem_share  rep_share  \n",
       " 0   0.629943   0.186495   0.015244      0.144035   0.308879   0.670312  \n",
       " 1   0.535046   0.117933   0.073266      0.253889   0.308623   0.670572  \n",
       " 2   0.578076   0.114005   0.108806      0.174107   0.308510   0.670685  \n",
       " 3   0.608467   0.097559   0.156080      0.108975   0.308504   0.670681  \n",
       " 4   0.515702   0.161955   0.038687      0.263356   0.308515   0.670684  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Building a Feature Matrix\n",
    "* The helper function `build_features` creates a feature matrix from our Pandas dataframe.\n",
    "* `drop_race` is a boolean flag which determines whether or not racial composition features will be included in our feature matrix.\n",
    "* The `district_id` is dropped before returning the feature matrix."
   ],
   "id": "67f80c0249abb1aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_features(df, drop_race: bool):\n",
    "    cols = [c for c in df.columns if c != ID_COL]\n",
    "    if drop_race:\n",
    "        cols = [c for c in cols if c not in RACE_COLS]\n",
    "    return df[cols].copy(), cols"
   ],
   "id": "8a46db02e4836429"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Building a Feature Matrix that Includes All Features\n",
    "* This matrix will have the columns `polsby_popper`, `schwartzberg`, `convex_hull_ratio`, `reock`, `pct_white`, `pct_black`, `pct_asian`, `pct_hispanic`, `dem_share`, and `rep_share`.\n",
    "* Hence, the full feature matrix will have 38 rows and 10 columns."
   ],
   "id": "a736633696b9243"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_full, full_cols = build_features(df, drop_race=False)\n",
    "scaler_full = StandardScaler()\n",
    "X_full_scaled = scaler_full.fit_transform(X_full)"
   ],
   "id": "a45deaa283975917"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Building a Feature Matrix that Does NOT Include Racial Composition Features\n",
    "* This feature matrix that excludes racial features will have the columns `polsby_popper`, `schwartzberg`, `convex_hull_ratio`, `reock`, `dem_share`, and `rep_share`.\n",
    "* Hence, this feature matrix has 38 rows and 6 columns."
   ],
   "id": "20900f40a894c470"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T01:15:18.353463Z",
     "start_time": "2025-09-25T01:15:18.346370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_norace, norace_cols = build_features(df, drop_race=True)\n",
    "scaler_norace = StandardScaler()\n",
    "X_norace_scaled = scaler_norace.fit_transform(X_norace)"
   ],
   "id": "812e3cf01142ee26",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T01:15:18.404751Z",
     "start_time": "2025-09-25T01:15:18.397446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save artifacts\n",
    "joblib.dump(scaler_full, f\"{ART_DIR}/scaler_full.joblib\")\n",
    "np.savez(f\"{ART_DIR}/X_full_scaled.npz\", X=X_full_scaled)\n",
    "with open(f\"{ART_DIR}/full_columns.json\", \"w\") as f: json.dump(full_cols, f)\n",
    "\n",
    "joblib.dump(scaler_norace, f\"{ART_DIR}/scaler_norace.joblib\")\n",
    "np.savez(f\"{ART_DIR}/X_norace_scaled.npz\", X=X_norace_scaled)\n",
    "with open(f\"{ART_DIR}/norace_columns.json\", \"w\") as f: json.dump(norace_cols, f)\n",
    "\n",
    "df[[ID_COL]].to_csv(f\"{ART_DIR}/district_ids.csv\", index=False)\n",
    "df.to_csv(f\"{ART_DIR}/dataset_snapshot.csv\", index=False)\n",
    "print(\"Artifacts saved in\", ART_DIR)"
   ],
   "id": "281031564cc5dd65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved in artifacts\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
