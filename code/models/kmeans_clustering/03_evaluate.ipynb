{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate clustering using Silhouette Score.",
   "id": "9bb27d001150739b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate clustering using Adjusted Rand index.",
   "id": "a50b6e5ba02c03e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate classification using the classification report.",
   "id": "2d509fc0ecda635b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_X(variant):\n",
    "    return np.load(f\"{ART_DIR}/X_{variant}_scaled.npz\")[\"X\"]\n",
    "\n",
    "df = pd.read_csv(f\"{ART_DIR}/dataset_snapshot.csv\")\n",
    "\n",
    "def eval_variant(variant):\n",
    "    clusters_path = f\"{ART_DIR}/clusters_{variant}.csv\"\n",
    "    meta_path = f\"{ART_DIR}/trainmeta_{variant}.json\"\n",
    "    if not (os.path.exists(clusters_path) and os.path.exists(meta_path)):\n",
    "        print(\"Missing\", variant)\n",
    "        return\n",
    "\n",
    "    with open(meta_path) as f: meta = json.load(f)\n",
    "    print(\"=\"*50, f\"\\\\nVariant: {variant}\")\n",
    "    print(\"Best k:\", meta[\"best_k\"], \"Silhouette:\", meta[\"silhouette\"])\n",
    "\n",
    "    clusters = pd.read_csv(clusters_path)\n",
    "    merged = df.merge(clusters, on=ID_COL, how=\"left\")\n",
    "    cluster_col = f\"cluster_{variant}\"\n",
    "\n",
    "    if set(RACE_COLS).issubset(merged.columns):\n",
    "        print(\"\\\\nAverage racial composition:\")\n",
    "        print(merged.groupby(cluster_col)[RACE_COLS].mean())\n",
    "\n",
    "    X = load_X(variant)\n",
    "    labels = merged[cluster_col]\n",
    "    print(\"Silhouette (recomputed):\", silhouette_score(X, labels))\n",
    "\n",
    "    pca = PCA(2, random_state=42)\n",
    "    Xt = pca.fit_transform(X)\n",
    "    plt.scatter(Xt[:,0], Xt[:,1], c=labels)\n",
    "    plt.title(f\"PCA â€” {variant}\")\n",
    "    plt.show()\n",
    "\n",
    "eval_variant(\"full\")\n",
    "eval_variant(\"norace\")\n",
    "\n",
    "# Compare stability\n",
    "cf = pd.read_csv(f\"{ART_DIR}/clusters_full.csv\")\n",
    "cn = pd.read_csv(f\"{ART_DIR}/clusters_norace.csv\")\n",
    "m = cf.merge(cn, on=ID_COL)\n",
    "ari = adjusted_rand_score(m[\"cluster_full\"], m[\"cluster_norace\"])\n",
    "print(\"\\\\nStability (ARI full vs. no-race):\", ari)"
   ],
   "id": "c58b972f49102a54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
