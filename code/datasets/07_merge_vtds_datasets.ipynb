{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Needed Libraries and Filepaths",
   "id": "26662965072d83dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.050993Z",
     "start_time": "2025-09-19T22:08:02.048138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from texas_gerrymandering_hb4.config import INTERIM_DATA_DIR, CLEAN_ELECTION_RESULTS, CLEAN_VTD_GEO\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import sys\n",
    "import pyarrow"
   ],
   "id": "3a5e6d7e583a6a34",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.073047Z",
     "start_time": "2025-09-19T22:08:02.070539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inner_parquet = INTERIM_DATA_DIR/\"inner_join_vtds.parquet\"\n",
    "left_parquet = INTERIM_DATA_DIR/\"left_join_vtds.parquet\""
   ],
   "id": "393b9d26bb677b02",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper Functions",
   "id": "d5a2785a7c140b79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.128436Z",
     "start_time": "2025-09-19T22:08:02.120658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------ Helpers ------------------------\n",
    "def to_str_or_none(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, float) and math.isnan(x):\n",
    "        return None\n",
    "    return str(x)\n",
    "\n",
    "def clean_digits(x):\n",
    "    s = to_str_or_none(x)\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"\\D\", \"\", s)   # keep digits only\n",
    "    return s if s else None\n",
    "\n",
    "def build_cntyvtd_norm_from_fips_vtd(fips, vtd):\n",
    "    f = clean_digits(fips)\n",
    "    v = clean_digits(vtd)\n",
    "    if not f or not v:\n",
    "        return None\n",
    "    return f.zfill(3) + v.zfill(4)   # CCC + VVVV\n",
    "\n",
    "def normalize_cntyvtd_string(raw, fallback_fips=None):\n",
    "    \"\"\"\n",
    "    Normalize any CNTYVTD-like string into 7-digit CCCVVVV.\n",
    "    If it's 7 digits already, keep it.\n",
    "    If it's 6 => assume 3+3 and pad VTD to 4.\n",
    "    If it's 5 => often CC+VVV; upgrade to CCC+VVVV by zfilling.\n",
    "    If it's 4 => VTD only -> need fallback_fips to build.\n",
    "    Otherwise try to coerce by padding left.\n",
    "    \"\"\"\n",
    "    s = clean_digits(raw)\n",
    "    if s is None:\n",
    "        # try fallback with vtd-only branch below by passing raw again\n",
    "        if fallback_fips is not None:\n",
    "            return build_cntyvtd_norm_from_fips_vtd(fallback_fips, raw)\n",
    "        return None\n",
    "\n",
    "    if len(s) == 7:\n",
    "        return s\n",
    "    if len(s) == 6:\n",
    "        return s[:3] + s[3:].zfill(4)\n",
    "    if len(s) == 5:\n",
    "        return s[:2].zfill(3) + s[2:].zfill(4)\n",
    "    if len(s) == 4:\n",
    "        if fallback_fips is not None:\n",
    "            return build_cntyvtd_norm_from_fips_vtd(fallback_fips, s)\n",
    "        return None\n",
    "    # odd lengths: pad to 7 on the left as last resort\n",
    "    return s.zfill(7)\n",
    "\n",
    "def freq_len(series):\n",
    "    return series.dropna().astype(str).str.len().value_counts().sort_index()"
   ],
   "id": "d5560508726db94e",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "21601bfccb6431a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.201054Z",
     "start_time": "2025-09-19T22:08:02.177245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Election Results\n",
    "df = pd.read_csv(CLEAN_ELECTION_RESULTS)"
   ],
   "id": "5f480c858e868804",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.354874Z",
     "start_time": "2025-09-19T22:08:02.226967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# VTD Geospatial Data\n",
    "gdf = gpd.read_parquet(CLEAN_VTD_GEO)"
   ],
   "id": "10a104184487bdb2",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.364865Z",
     "start_time": "2025-09-19T22:08:02.362761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------ Column cleanup ------------------------\n",
    "gdf.columns = [c.strip() for c in gdf.columns]\n",
    "df.columns  = [c.strip().lower() for c in df.columns]"
   ],
   "id": "99431504a89ddd20",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.418377Z",
     "start_time": "2025-09-19T22:08:02.412759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------ Build normalized keys ------------------------\n",
    "# GEO side: prefer existing CNTYVTD (DO NOT use CNTY as FIPS fallback — it may not be FIPS)\n",
    "if \"cntyvtd\" in gdf.columns and \"CNTYVTD\" not in gdf.columns:\n",
    "    gdf.rename(columns={\"cntyvtd\": \"CNTYVTD\"}, inplace=True)\n",
    "\n",
    "if \"CNTYVTD\" not in gdf.columns:\n",
    "    # If we truly don't have CNTYVTD, only then try CNTY + VTD (but this is riskier)\n",
    "    if {\"CNTY\", \"VTD\"}.issubset(gdf.columns):\n",
    "        gdf[\"CNTYVTD\"] = [\n",
    "            build_cntyvtd_norm_from_fips_vtd(gdf.loc[i, \"CNTY\"], gdf.loc[i, \"VTD\"])\n",
    "            for i in gdf.index\n",
    "        ]\n",
    "    else:\n",
    "        raise KeyError(\"Geo file missing CNTYVTD and (CNTY,VTD). Please ensure CNTYVTD exists in the geo dataset.\")\n"
   ],
   "id": "7ee30a1a93ceac0b",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.482908Z",
     "start_time": "2025-09-19T22:08:02.466036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize to 7-digit string\n",
    "gdf[\"cntyvtd_norm\"] = gdf[\"CNTYVTD\"].map(lambda x: normalize_cntyvtd_string(x))"
   ],
   "id": "e69ccbe5b36a1e5e",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.613712Z",
     "start_time": "2025-09-19T22:08:02.521217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RESULTS side: **build from fips + vtd** whenever possible (most reliable)\n",
    "have_fips = any(c in df.columns for c in [\"fips\",\"county_fips\",\"countyfp\",\"cnty\"])\n",
    "fips_col = next((c for c in [\"fips\",\"county_fips\",\"countyfp\",\"cnty\"] if c in df.columns), None)\n",
    "vtd_col  = \"vtd\" if \"vtd\" in df.columns else None\n",
    "\n",
    "if fips_col and vtd_col:\n",
    "    df[\"cntyvtd_norm\"] = [\n",
    "        build_cntyvtd_norm_from_fips_vtd(df.loc[i, fips_col], df.loc[i, vtd_col])\n",
    "        for i in df.index\n",
    "    ]\n",
    "elif \"cntyvtd\" in df.columns:\n",
    "    # Fall back to normalizing the provided string and (if we have a fips column) use it as fallback\n",
    "    fallback = df[fips_col] if fips_col else None\n",
    "    df[\"cntyvtd_norm\"] = [\n",
    "        normalize_cntyvtd_string(df.loc[i, \"cntyvtd\"], fallback_fips=(fallback.iloc[i] if fallback is not None else None))\n",
    "        for i in df.index\n",
    "    ]\n",
    "else:\n",
    "    raise KeyError(\"Results file missing both (fips,vtd) and cntyvtd. Need one of those to build the key.\")"
   ],
   "id": "733372526d472509",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.711926Z",
     "start_time": "2025-09-19T22:08:02.617663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize to 7-digit string\n",
    "gdf[\"cntyvtd_norm\"] = gdf[\"CNTYVTD\"].map(lambda x: normalize_cntyvtd_string(x))\n",
    "\n",
    "# RESULTS side: **build from fips + vtd** whenever possible (most reliable)\n",
    "have_fips = any(c in df.columns for c in [\"fips\",\"county_fips\",\"countyfp\",\"cnty\"])\n",
    "fips_col = next((c for c in [\"fips\",\"county_fips\",\"countyfp\",\"cnty\"] if c in df.columns), None)\n",
    "vtd_col  = \"vtd\" if \"vtd\" in df.columns else None\n",
    "\n",
    "if fips_col and vtd_col:\n",
    "    df[\"cntyvtd_norm\"] = [\n",
    "        build_cntyvtd_norm_from_fips_vtd(df.loc[i, fips_col], df.loc[i, vtd_col])\n",
    "        for i in df.index\n",
    "    ]\n",
    "elif \"cntyvtd\" in df.columns:\n",
    "    # Fall back to normalizing the provided string and (if we have a fips column) use it as fallback\n",
    "    fallback = df[fips_col] if fips_col else None\n",
    "    df[\"cntyvtd_norm\"] = [\n",
    "        normalize_cntyvtd_string(df.loc[i, \"cntyvtd\"], fallback_fips=(fallback.iloc[i] if fallback is not None else None))\n",
    "        for i in df.index\n",
    "    ]\n",
    "else:\n",
    "    raise KeyError(\"Results file missing both (fips,vtd) and cntyvtd. Need one of those to build the key.\")"
   ],
   "id": "bc8950cc2b72e1a8",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.733752Z",
     "start_time": "2025-09-19T22:08:02.716134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------ Diagnostics ------------------------\n",
    "print(\"Geo key length distribution:\\n\", freq_len(gdf[\"cntyvtd_norm\"]))\n",
    "print(\"Res key length distribution:\\n\", freq_len(df[\"cntyvtd_norm\"]))\n",
    "\n",
    "geo_null = gdf[\"cntyvtd_norm\"].isna().sum()\n",
    "res_null = df[\"cntyvtd_norm\"].isna().sum()\n",
    "print(f\"Null geo keys: {geo_null}/{len(gdf)}\")\n",
    "print(f\"Null res keys: {res_null}/{len(df)}\")\n",
    "\n",
    "geo_keys = set(gdf[\"cntyvtd_norm\"].dropna().unique())\n",
    "res_keys = set(df[\"cntyvtd_norm\"].dropna().unique())\n",
    "\n",
    "only_in_geo = sorted(geo_keys - res_keys)[:15]\n",
    "only_in_res = sorted(res_keys - geo_keys)[:15]\n",
    "print(\"Only-in-geo sample:\", only_in_geo)\n",
    "print(\"Only-in-results sample:\", only_in_res)"
   ],
   "id": "1e1191df0eadccad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geo key length distribution:\n",
      " cntyvtd_norm\n",
      "7    9703\n",
      "Name: count, dtype: int64\n",
      "Res key length distribution:\n",
      " cntyvtd_norm\n",
      "7    9712\n",
      "Name: count, dtype: int64\n",
      "Null geo keys: 9/9712\n",
      "Null res keys: 0/9712\n",
      "Only-in-geo sample: ['0100001', '0100002', '0100003', '0100004', '0100005', '0100006', '0100007', '0100008', '0100009', '0100010', '0100011', '0100013', '0100015', '0100016', '0100017']\n",
      "Only-in-results sample: ['0010001', '0010002', '0010003', '0010004', '0010005', '0010006', '0010007', '0010008', '0010009', '0010010', '0010011', '0010013', '0010015', '0010016', '0010017']\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.789863Z",
     "start_time": "2025-09-19T22:08:02.772845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If duplicates in results, aggregate sensibly\n",
    "vote_cols = [c for c in [\"dem_votes\",\"rep_votes\",\"third_party_votes\",\"total_votes\",\"dem_share\"] if c in df.columns]\n",
    "if df[\"cntyvtd_norm\"].duplicated().any():\n",
    "    agg_map = {c: \"sum\" for c in vote_cols if c != \"dem_share\"}\n",
    "    df_agg = df.groupby(\"cntyvtd_norm\", as_index=False).agg(agg_map)\n",
    "    if {\"dem_votes\",\"total_votes\"}.issubset(df_agg.columns):\n",
    "        df_agg[\"dem_share\"] = df_agg[\"dem_votes\"] / df_agg[\"total_votes\"].replace({0: pd.NA})\n",
    "else:\n",
    "    df_agg = df.copy()"
   ],
   "id": "22121b9f2dcec39",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:02.848845Z",
     "start_time": "2025-09-19T22:08:02.826195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------ Joins ------------------------\n",
    "inner = gdf.merge(df_agg, on=\"cntyvtd_norm\", how=\"inner\")\n",
    "left  = gdf.merge(df_agg, on=\"cntyvtd_norm\", how=\"left\")\n",
    "\n",
    "# Fill vote NaNs with 0 on left; recompute share if possible\n",
    "for c in vote_cols:\n",
    "    if c in left.columns and c != \"dem_share\":\n",
    "        left[c] = left[c].fillna(0).astype(\"Int64\")\n",
    "if {\"dem_votes\",\"total_votes\"}.issubset(left.columns):\n",
    "    left[\"dem_share\"] = (left[\"dem_votes\"].astype(\"Int64\").fillna(0) /\n",
    "                         left[\"total_votes\"].replace({0: pd.NA}))\n",
    "\n",
    "print(f\"Rows — geo: {len(gdf)}, results(agg): {len(df_agg)}, inner: {len(inner)}, left: {len(left)}\")"
   ],
   "id": "2d6b29e48d3c120",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows — geo: 9712, results(agg): 9389, inner: 339, left: 9712\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:08:03.123769Z",
     "start_time": "2025-09-19T22:08:02.885020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exports\n",
    "#inner.drop(columns=[\"geometry\"], errors=\"ignore\").to_csv(INTERIM_DATA_DIR/\"inner_join_vtds.csv\", index=False)\n",
    "#left.drop(columns=[\"geometry\"], errors=\"ignore\").to_csv(INTERIM_DATA_DIR/\"left_join_vtds.csv\", index=False)\n",
    "\n",
    "# GeoPackage + GeoParquet\n",
    "#inner.to_file(INTERIM_DATA_DIR/\"vtd_merged.gpkg\", layer=\"vtd_merged_inner\", driver=\"GPKG\")\n",
    "#left.to_file(INTERIM_DATA_DIR/\"vtd_merged.gpkg\", layer=\"vtd_merged_left\", driver=\"GPKG\")\n",
    "\n",
    "# If parquet environment is ready:\n",
    "inner.to_parquet(inner_parquet)\n",
    "left.to_parquet(left_parquet)"
   ],
   "id": "e178261e97371b34",
   "outputs": [],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
