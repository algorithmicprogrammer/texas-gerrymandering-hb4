{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Needed Filepaths & Libraries",
   "id": "833e29d77f7701cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:10.090977Z",
     "start_time": "2025-09-16T19:50:10.088217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from texas_gerrymandering_hb4.config import INTERIM_DATA_DIR, CENSUS_DEMOGRAPHICS_TXT\n",
    "import duckdb"
   ],
   "id": "2b14c293e02ec5ea",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Start DuckDB Session",
   "id": "7224ec09abe70041"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:10.144504Z",
     "start_time": "2025-09-16T19:50:10.134948Z"
    }
   },
   "cell_type": "code",
   "source": "con = duckdb.connect()",
   "id": "6c8e5c52174b2dca",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Registering the Raw Data as a DuckDB Views",
   "id": "4747307ffb361854"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:10.335566Z",
     "start_time": "2025-09-16T19:50:10.186534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "con.execute(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW raw_view AS\n",
    "  SELECT * FROM read_csv_auto('{CENSUS_DEMOGRAPHICS_TXT}', header=True)\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "  CREATE OR REPLACE VIEW raw_view_str AS\n",
    "  SELECT * FROM read_csv_auto('{CENSUS_DEMOGRAPHICS_TXT}', header=True, ALL_VARCHAR=TRUE)\n",
    "\"\"\")"
   ],
   "id": "2419978ddd00fe4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7c3e3c0765b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Counting the Number of Rows in Raw Data",
   "id": "168aae1a22f84c52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:10.475487Z",
     "start_time": "2025-09-16T19:50:10.349465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Row count:\")\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_rows FROM raw_view\").df())"
   ],
   "id": "89b4e9c1df1d0100",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count:\n",
      "   n_rows\n",
      "0  668757\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Printing Attribute Names & Rows in Raw Data",
   "id": "208f112c7566f74d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:10.492223Z",
     "start_time": "2025-09-16T19:50:10.488330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nColumn names and types:\")\n",
    "print(con.execute(\"PRAGMA table_info('raw_view')\").df())"
   ],
   "id": "ec5c4d168d4861fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column names and types:\n",
      "    cid        name     type  notnull dflt_value     pk\n",
      "0     0         FID   BIGINT    False       None  False\n",
      "1     1          BG   BIGINT    False       None  False\n",
      "2     2       State   BIGINT    False       None  False\n",
      "3     3         TRT  VARCHAR    False       None  False\n",
      "4     4         BLK  VARCHAR    False       None  False\n",
      "5     5     SCTBKEY   BIGINT    False       None  False\n",
      "6     6      blkkey   BIGINT    False       None  False\n",
      "7     7      CTBKEY  VARCHAR    False       None  False\n",
      "8     8        FIPS  VARCHAR    False       None  False\n",
      "9     9      FENAME  VARCHAR    False       None  False\n",
      "10   10       anglo   BIGINT    False       None  False\n",
      "11   11       asian   BIGINT    False       None  False\n",
      "12   12        hisp   BIGINT    False       None  False\n",
      "13   13       total   BIGINT    False       None  False\n",
      "14   14         vap   BIGINT    False       None  False\n",
      "15   15       black   BIGINT    False       None  False\n",
      "16   16          bh   BIGINT    False       None  False\n",
      "17   17      nanglo   BIGINT    False       None  False\n",
      "18   18    anglovap   BIGINT    False       None  False\n",
      "19   19     hispvap   BIGINT    False       None  False\n",
      "20   20       bhvap   BIGINT    False       None  False\n",
      "21   21    blackvap   BIGINT    False       None  False\n",
      "22   22    asianvap   BIGINT    False       None  False\n",
      "23   23   nanglovap   BIGINT    False       None  False\n",
      "24   24  Shape_Leng   DOUBLE    False       None  False\n",
      "25   25  Shape_Ar_1   DOUBLE    False       None  False\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking for Missing Values",
   "id": "645a2ecf27f312f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:10.736803Z",
     "start_time": "2025-09-16T19:50:10.542295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get schema (column names/types) into a DataFrame\n",
    "schema_df = con.execute(\"PRAGMA table_info('raw_view')\").df()\n",
    "\n",
    "# Extract column names into a Python list\n",
    "cols = schema_df[\"name\"].tolist()\n",
    "\n",
    "cols = schema_df[\"name\"].tolist()\n",
    "\n",
    "exprs = [\n",
    "    f\"SUM(CASE WHEN \\\"{c}\\\" IS NULL OR CAST(\\\"{c}\\\" AS VARCHAR) = '' THEN 1 ELSE 0 END) AS missing_{c.lower()}\"\n",
    "    for c in cols\n",
    "]\n",
    "\n",
    "sql_missing = \"SELECT \" + \",\\n       \".join(exprs) + \" FROM raw_view\"\n",
    "\n",
    "missing_df = con.execute(sql_missing).df().T.reset_index()\n",
    "missing_df.columns = [\"column\", \"missing_count\"]\n",
    "\n",
    "print(\"\\n=== RAW: Missing values per column ===\")\n",
    "display(missing_df.sort_values(\"missing_count\", ascending=False))\n"
   ],
   "id": "3521d0d1f5fd8a8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAW: Missing values per column ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                column  missing_count\n",
       "0          missing_fid            0.0\n",
       "1           missing_bg            0.0\n",
       "2        missing_state            0.0\n",
       "3          missing_trt            0.0\n",
       "4          missing_blk            0.0\n",
       "5      missing_sctbkey            0.0\n",
       "6       missing_blkkey            0.0\n",
       "7       missing_ctbkey            0.0\n",
       "8         missing_fips            0.0\n",
       "9       missing_fename            0.0\n",
       "10       missing_anglo            0.0\n",
       "11       missing_asian            0.0\n",
       "12        missing_hisp            0.0\n",
       "13       missing_total            0.0\n",
       "14         missing_vap            0.0\n",
       "15       missing_black            0.0\n",
       "16          missing_bh            0.0\n",
       "17      missing_nanglo            0.0\n",
       "18    missing_anglovap            0.0\n",
       "19     missing_hispvap            0.0\n",
       "20       missing_bhvap            0.0\n",
       "21    missing_blackvap            0.0\n",
       "22    missing_asianvap            0.0\n",
       "23   missing_nanglovap            0.0\n",
       "24  missing_shape_leng            0.0\n",
       "25  missing_shape_ar_1            0.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing_fid</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>missing_bg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>missing_state</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing_trt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_blk</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>missing_sctbkey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>missing_blkkey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>missing_ctbkey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>missing_fips</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>missing_fename</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>missing_anglo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>missing_asian</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>missing_hisp</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>missing_total</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>missing_vap</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>missing_black</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>missing_bh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>missing_nanglo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>missing_anglovap</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>missing_hispvap</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>missing_bhvap</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>missing_blackvap</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>missing_asianvap</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>missing_nanglovap</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>missing_shape_leng</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>missing_shape_ar_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a Cleaned Table in DuckDB",
   "id": "8473091c95e9336c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:11.072742Z",
     "start_time": "2025-09-16T19:50:10.744471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE pl94_clean AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    -- ---- Join key (already full 15-digit 2020 block GEOID) ----\n",
    "    CAST(SCTBKEY  AS VARCHAR) AS geoid20,\n",
    "\n",
    "    -- ---- Totals ----\n",
    "    CAST(total    AS BIGINT)  AS total_pop,\n",
    "    CAST(vap      AS BIGINT)  AS vap_total,\n",
    "\n",
    "    -- ---- Race/Ethnicity counts (TOTAL) ----\n",
    "    CAST(anglo    AS BIGINT)  AS nh_white,\n",
    "    CAST(black    AS BIGINT)  AS nh_black,\n",
    "    CAST(asian    AS BIGINT)  AS nh_asian,\n",
    "    CAST(hisp     AS BIGINT)  AS hispanic,\n",
    "\n",
    "    -- ---- Race/Ethnicity counts (VAP) ----\n",
    "    CAST(anglovap AS BIGINT)  AS nh_white_vap,\n",
    "    CAST(blackvap AS BIGINT)  AS nh_black_vap,\n",
    "    CAST(asianvap AS BIGINT)  AS nh_asian_vap,\n",
    "    CAST(hispvap  AS BIGINT)  AS hispanic_vap\n",
    "\n",
    "  FROM read_csv_auto('{CENSUS_DEMOGRAPHICS_TXT}', header=True)\n",
    "),\n",
    "shares AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    -- ---- Shares (TOTAL) ----\n",
    "    (nh_white  ::DOUBLE / NULLIF(total_pop,0)) AS share_nh_white_total,\n",
    "    (nh_black  ::DOUBLE / NULLIF(total_pop,0)) AS share_nh_black_total,\n",
    "    (nh_asian  ::DOUBLE / NULLIF(total_pop,0)) AS share_nh_asian_total,\n",
    "    (hispanic  ::DOUBLE / NULLIF(total_pop,0)) AS share_hispanic_total,\n",
    "\n",
    "    -- ---- Shares (VAP) ----\n",
    "    (nh_white_vap  ::DOUBLE / NULLIF(vap_total,0)) AS share_nh_white_vap,\n",
    "    (nh_black_vap  ::DOUBLE / NULLIF(vap_total,0)) AS share_nh_black_vap,\n",
    "    (nh_asian_vap  ::DOUBLE / NULLIF(vap_total,0)) AS share_nh_asian_vap,\n",
    "    (hispanic_vap  ::DOUBLE / NULLIF(vap_total,0)) AS share_hispanic_vap\n",
    "  FROM base\n",
    "),\n",
    "qa AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    -- Optional residuals for quick QA (can drop later if you want)\n",
    "    GREATEST(total_pop - COALESCE(nh_white,0) - COALESCE(nh_black,0) - COALESCE(nh_asian,0) - COALESCE(hispanic,0), 0) AS other_pop,\n",
    "    GREATEST(vap_total - COALESCE(nh_white_vap,0) - COALESCE(nh_black_vap,0) - COALESCE(nh_asian_vap,0) - COALESCE(hispanic_vap,0), 0) AS other_vap\n",
    "  FROM shares\n",
    ")\n",
    "SELECT * FROM qa;\n",
    "\"\"\")"
   ],
   "id": "d9dfbc2a1d2d02cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7c3e3c0765b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The cleaned DuckDB table has the following schema:\n",
    "\n",
    "| Column               | Type    | Description                                                                            |\n",
    "|----------------------|---------|----------------------------------------------------------------------------------------|\n",
    "| geoid20              | VARCHAR | Primary key to join with shapefile                                                     |\n",
    "| total_pop            | BIGINT  | Total population                                                                       |\n",
    "| vap_total            | BIGINT  | Voting age population                                                                  |\n",
    "| nh_white             | BIGINT  | Non-Hispanic white total population                                                    |\n",
    "| nh_black             | BIGINT  | Non-Hispanic black total population                                                    |\n",
    "| nh_asian             | BIGINT  | Non-Hispanic Asian total population                                                    |\n",
    "| hispanic             | BIGINT  | Hispanic/Latino population (any race)                                                  |\n",
    "| nh_white_vap         | BIGINT  | Non-Hispanic white voting age population                                               |\n",
    "| nh_black_vap         | BIGINT  | Non-Hispanic black voting age population                                               |\n",
    "| nh_asian_vap         | BIGINT  | Hispanic/Latino population (any race)                                                  |\n",
    "| hispanic_vap         | BIGINT  | Hispanic/Latino voting age population)                                                 |\n",
    "| share_nh_white_total | DOUBLE  | % non-Hispanic white population                                                        |\n",
    "| share_nh_black_total | DOUBLE  | % non-Hispanic black total population                                                  |\n",
    "| share_nh_asian_total | DOUBLE  | % non-Hispanic Asian total population                                                  |\n",
    "| share_hispanic_total | DOUBLE  | % Hispanic total population                                                            |\n",
    "| share_nh_white_vap   | DOUBLE  | % non-Hispanic white voting age population                                             |\n",
    "| share_nh_asian_vap   | DOUBLE  | % non-Hispanic Asian voting age population                                             |\n",
    "| share_hispanic_vap   | DOUBLE  | % Hispanic voting age population                                                       |\n",
    "| other_pop            | BIGINT  | Population not accounted for in white, black, Asian, or Hispanic categories            |\n",
    "| other_vap            | BIGINT  | Voting age population not accounted for in white, black, Asian, or Hispanic categories |"
   ],
   "id": "318d09bf0f0562a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Print How Many Census Blocks were Parsed",
   "id": "344bd4d3be40cfc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:11.083173Z",
     "start_time": "2025-09-16T19:50:11.080354Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Row count:\", con.execute(\"SELECT COUNT(*) FROM pl94_clean\").fetchone()[0])",
   "id": "d77fc81373ec6bc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 668757\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparing Total Population Versus Racial Demographics",
   "id": "c71cfb212df0ccc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:11.141805Z",
     "start_time": "2025-09-16T19:50:11.128990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(con.execute(\"\"\"\n",
    "SELECT\n",
    "  SUM(total_pop)                           AS sum_total,\n",
    "  SUM(nh_white + nh_black + nh_asian + hispanic + other_pop) AS sum_parts\n",
    "FROM pl94_clean;\n",
    "\"\"\").df())\n",
    "\n",
    "print(con.execute(\"\"\"\n",
    "SELECT\n",
    "  SUM(vap_total)                            AS sum_vap_total,\n",
    "  SUM(nh_white_vap + nh_black_vap + nh_asian_vap + hispanic_vap + other_vap) AS sum_vap_parts\n",
    "FROM pl94_clean;\n",
    "\"\"\").df())"
   ],
   "id": "ea0d09c5c4f0795b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sum_total   sum_parts\n",
      "0  29145505.0  29324461.0\n",
      "   sum_vap_total  sum_vap_parts\n",
      "0     21866700.0     21956709.0\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Export Cleaned Table to Parquet Table",
   "id": "e125d44b411abd42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:50:11.267873Z",
     "start_time": "2025-09-16T19:50:11.178308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "con.execute(f\"COPY pl94_clean TO '{INTERIM_DATA_DIR}/tx_pl94_clean.parquet' (FORMAT PARQUET);\")\n",
    "\n",
    "print(\"Wrote:\", INTERIM_DATA_DIR / \"tx_pl94_clean.parquet\")"
   ],
   "id": "1973a3e6182a7b1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/aimlexpert/Documents/GitHub/texas-gerrymandering-HB4/data/interim/tx_pl94_clean.parquet\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
