{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Needed Libraries",
   "id": "a664d60447554dcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List"
   ],
   "id": "de1148ee447044fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Computing the Democratic Two-Party Vote Share\n",
    "$$dem\\_share\\_2p = \\frac{D}{D+R}$$"
   ],
   "id": "5fe77fa375d0797d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def to_two_party_share(df: pd.DataFrame, dem_col: str, rep_col: str, out_col: str) -> pd.DataFrame:\n",
    "    dem = df[dem_col].astype(float)\n",
    "    rep = df[rep_col].astype(float)\n",
    "    s = dem + rep\n",
    "    df[out_col] = np.where(s > 0, dem / s, np.nan)\n",
    "    return df"
   ],
   "id": "2525a97c7e57b91c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Re-Normalizing Race Proportion Columns\n",
    "Ensuring the race proportions sum to ~1 per row by renormalizing."
   ],
   "id": "d04f3a67109a569e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def normalize_race_props(df: pd.DataFrame, race_cols: List[str], tol: float = 1e-6) -> pd.DataFrame:\n",
    "    s = df[race_cols].sum(axis=1)\n",
    "    df[race_cols] = np.where(\n",
    "        (s.values[:, None] > tol),\n",
    "        df[race_cols].values / s.values[:, None],\n",
    "        df[race_cols].values\n",
    "    )\n",
    "    return df"
   ],
   "id": "33fb8cd9e243532e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Computation of Gini Coefficient\n",
    "* The Gini coefficient is a dispersion/inequality metric.\n",
    "* It is used to assess how unevenly the minority population distributed across voting tabulation districts across congressional districts."
   ],
   "id": "5cfa71cc0317b32d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def gini(x) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    if np.allclose(x, 0):\n",
    "        return 0.0\n",
    "    x = np.sort(x)\n",
    "    n = x.size\n",
    "    cumx = np.cumsum(x)\n",
    "    return (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n"
   ],
   "id": "12038522c73cc107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build a Clean VTD-Level Feature Table",
   "id": "5ff2c567e675d48c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_vtd_units(\n",
    "    df_raw: pd.DataFrame,\n",
    "    vtd_id_col: str,\n",
    "    cd_col: str,\n",
    "    pop_col: str,\n",
    "    dem_col: str,\n",
    "    rep_col: str,\n",
    "    dem_share_2p_col: str,\n",
    "    race_cols: List[str],\n",
    ") -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    for c in [vtd_id_col, cd_col]:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {c}\")\n",
    "\n",
    "    if pop_col not in df.columns:\n",
    "        df[pop_col] = 1.0\n",
    "\n",
    "    if dem_share_2p_col not in df.columns:\n",
    "        if dem_col not in df.columns or rep_col not in df.columns:\n",
    "            raise ValueError(f\"Need either {dem_share_2p_col} OR both {dem_col} and {rep_col}.\")\n",
    "        df = to_two_party_share(df, dem_col=dem_col, rep_col=rep_col, out_col=dem_share_2p_col)\n",
    "\n",
    "    missing = [c for c in race_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing race proportion columns: {missing}\")\n",
    "\n",
    "    df = normalize_race_props(df, race_cols=race_cols)\n",
    "\n",
    "    compactness_cols = [c for c in df.columns if c.startswith(\"compactness_\")]\n",
    "\n",
    "    keep = [vtd_id_col, cd_col, pop_col, dem_share_2p_col] + race_cols + compactness_cols\n",
    "    return df[keep].copy()"
   ],
   "id": "52ffdce750132ccd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Builds \"Long\" Elections Table\n",
    "Creates a long election table keyed by election_id and vtd_id."
   ],
   "id": "4eb1b75a13b5ff3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_elections_long(vtd_units: pd.DataFrame, vtd_id_col: str, dem_share_2p_col: str, election_id: str) -> pd.DataFrame:\n",
    "    return pd.DataFrame({\n",
    "        \"election_id\": election_id,\n",
    "        vtd_id_col: vtd_units[vtd_id_col].values,\n",
    "        \"dem_share_2p\": vtd_units[dem_share_2p_col].values,\n",
    "        \"rep_share_2p\": 1.0 - vtd_units[dem_share_2p_col].values,\n",
    "    })"
   ],
   "id": "cb8cdf65c07388c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aggregates VTD-Level Units to Congressional District-Level Features",
   "id": "a38022ea8788070d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_to_cd(\n",
    "    vtd_units: pd.DataFrame,\n",
    "    cd_col: str,\n",
    "    pop_col: str,\n",
    "    race_cols: List[str],\n",
    "    minority: str = \"black\",\n",
    "    coalition: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    df = vtd_units.copy()\n",
    "\n",
    "    if coalition:\n",
    "        df[\"p_minority\"] = df[\"p_black\"] + df[\"p_latino\"]\n",
    "    else:\n",
    "        key = f\"p_{minority}\"\n",
    "        if key not in df.columns:\n",
    "            raise ValueError(f\"Minority column not found: {key}\")\n",
    "        df[\"p_minority\"] = df[key]\n",
    "\n",
    "    def wavg(g: pd.DataFrame, col: str) -> float:\n",
    "        w = g[pop_col].values.astype(float)\n",
    "        x = g[col].values.astype(float)\n",
    "        return float(np.average(x, weights=w)) if np.sum(w) > 0 else np.nan\n",
    "\n",
    "    cd = df.groupby(cd_col, as_index=False).apply(\n",
    "        lambda g: pd.Series({\n",
    "            \"pop_total\": float(g[pop_col].sum()),\n",
    "            **{c: wavg(g, c) for c in race_cols},\n",
    "            \"minority_share\": wavg(g, \"p_minority\"),\n",
    "        })\n",
    "    ).reset_index(drop=True).rename(columns={cd_col: \"cd\"})\n",
    "\n",
    "    disp = df.groupby(cd_col).apply(lambda g: pd.Series({\n",
    "        \"minority_dispersion_var\": float(np.nanvar(g[\"p_minority\"].values)),\n",
    "        \"minority_dispersion_gini\": float(gini(g[\"p_minority\"].values)),\n",
    "        \"minority_top10_mean\": (\n",
    "            float(np.nanmean(np.sort(g[\"p_minority\"].values)[int(0.9*len(g)):]))\n",
    "            if len(g) >= 10 else np.nan\n",
    "        ),\n",
    "    })).reset_index().rename(columns={cd_col: \"cd\"})\n",
    "\n",
    "    cd = cd.merge(disp, on=\"cd\", how=\"left\")\n",
    "\n",
    "    compactness_cols = [c for c in df.columns if c.startswith(\"compactness_\")]\n",
    "    if compactness_cols:\n",
    "        comp = df[[cd_col] + compactness_cols].drop_duplicates(cd_col).rename(columns={cd_col: \"cd\"})\n",
    "        cd = cd.merge(comp, on=\"cd\", how=\"left\")\n",
    "\n",
    "    return cd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
