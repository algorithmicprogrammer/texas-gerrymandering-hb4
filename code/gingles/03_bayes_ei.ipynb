{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Needed Libraries",
   "id": "3cc83f768c6a3644"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* `numpy`: used for numerical arrays, inear algebra, and vectorized operations\n",
    "* `pandas`: used for tabular data manipulation\n",
    "* `arviz`: used for posterior analysis and diagnostics. Provides the InferenceData container that PyMC returns."
   ],
   "id": "bc829332af00bcc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az"
   ],
   "id": "613e67126a962897"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fit_bayesian_ecological_model(\n",
    "    vtd_units: pd.DataFrame,\n",
    "    cd_col: str,\n",
    "    dem_share_2p_col: str,\n",
    "    pop_col: str,\n",
    "    race_cols: List[str],\n",
    "    draws: int,\n",
    "    tune: int,\n",
    "    chains: int,\n",
    "    target_accept: float,\n",
    "    random_seed: int,\n",
    ") -> Tuple[pm.Model, az.InferenceData, List[str], pd.Index]:\n",
    "    df = vtd_units.copy().dropna(subset=[dem_share_2p_col])\n",
    "\n",
    "    cd_codes, cd_index = pd.factorize(df[cd_col])\n",
    "    X = df[race_cols].values.astype(float)          # (N,R)\n",
    "    y = df[dem_share_2p_col].values.astype(float)   # (N,)\n",
    "    w = df[pop_col].values.astype(float)            # (N,)\n",
    "\n",
    "    D = int(np.unique(cd_codes).size)\n",
    "    N, R = X.shape\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Hyperpriors on logit scale (BDA3-style regularization)\n",
    "        mu = pm.Normal(\"mu\", mu=0.0, sigma=1.5, shape=R)\n",
    "        tau = pm.HalfNormal(\"tau\", sigma=1.0, shape=R)\n",
    "\n",
    "        eta = pm.Normal(\"eta\", mu=mu, sigma=tau, shape=(D, R))\n",
    "        theta = pm.Deterministic(\"theta\", pm.math.sigmoid(eta))\n",
    "\n",
    "        mu_y = (theta[cd_codes] * X).sum(axis=1)\n",
    "\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=0.08)\n",
    "        sigma_i = sigma / pm.math.sqrt(pm.math.maximum(w, 1.0))\n",
    "\n",
    "        pm.Normal(\"y_obs\", mu=mu_y, sigma=sigma_i, observed=y)\n",
    "\n",
    "        idata = pm.sample(\n",
    "            draws=draws,\n",
    "            tune=tune,\n",
    "            chains=chains,\n",
    "            target_accept=target_accept,\n",
    "            random_seed=random_seed,\n",
    "        )\n",
    "\n",
    "        ppc = pm.sample_posterior_predictive(idata, var_names=[\"y_obs\"], random_seed=random_seed)\n",
    "        idata.extend(ppc)\n",
    "\n",
    "    return model, idata, race_cols, cd_index"
   ],
   "id": "72b3c9698e4c0d15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This function takes posterior draws of $\\theta$ and turns them into\n",
    "<ol>\n",
    "<li>per congressional district Democratic win probabilities under an enacted congressional district's racial composition</li>\n",
    "<li>plan-wide summary probabilities related to Gingles prong 3 style racial polarization metrics</li>\n",
    "</ol>"
   ],
   "id": "4ecbe0eed10cb2b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_gingles_posteriors(\n",
    "    idata: az.InferenceData,\n",
    "    race_cols: List[str],\n",
    "    cd_index: pd.Index,\n",
    "    cd_enacted_df: pd.DataFrame,\n",
    "    minority: str = \"black\",\n",
    "    coalition: bool = False,\n",
    "    delta: float = 0.15,\n",
    "    cohesion_thresh: float = 0.6,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, float]]:\n",
    "    theta = idata.posterior[\"theta\"]  # chain, draw, D, R\n",
    "    theta_s = theta.stack(sample=(\"chain\", \"draw\")).values  # (S, D, R)\n",
    "\n",
    "    race_to_j = {r: j for j, r in enumerate(race_cols)}\n",
    "    j_white = race_to_j[\"p_white\"]\n",
    "    if coalition:\n",
    "        j_min1 = race_to_j[\"p_black\"]\n",
    "        j_min2 = race_to_j[\"p_latino\"]\n",
    "    else:\n",
    "        j_min = race_to_j[f\"p_{minority}\"]\n",
    "\n",
    "    # Align CD compositions to the same order as factorization\n",
    "    cd = cd_enacted_df.copy().set_index(\"cd\").loc[cd_index]\n",
    "    M = cd[race_cols].values.astype(float)  # (D, R)\n",
    "\n",
    "    # Predicted district Dem share for each posterior sample\n",
    "    # (S,D,R) @ (R,D) -> (S,D)\n",
    "    Yhat = np.einsum(\"sdr,Dr->sD\", theta_s, M)\n",
    "\n",
    "    win_prob = (Yhat > 0.5).mean(axis=0)  # (D,)\n",
    "    cd_out = cd.reset_index()[[\"cd\"]].copy()\n",
    "    cd_out[\"win_prob_dem\"] = win_prob\n",
    "    cd_out[\"minority_share\"] = cd[\"minority_share\"].values\n",
    "\n",
    "    # Plan-wide Gingles #3 summaries\n",
    "    if coalition:\n",
    "        theta_min = 0.5 * (theta_s[:, :, j_min1] + theta_s[:, :, j_min2])\n",
    "    else:\n",
    "        theta_min = theta_s[:, :, j_min]\n",
    "    theta_white = theta_s[:, :, j_white]\n",
    "\n",
    "    gingles3 = {\n",
    "        \"P(minority cohesion)\": float((theta_min > cohesion_thresh).mean()),\n",
    "        \"P(white bloc voting)\": float((theta_white < 0.5).mean()),\n",
    "        f\"P(polarization gap > {delta})\": float(((theta_min - theta_white) > delta).mean()),\n",
    "    }\n",
    "    return cd_out, gingles3\n"
   ],
   "id": "71e7e576ae26d645"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Summarizing Convergence/Efficiency Diagnostics",
   "id": "ab84672ef30600bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diagnostics_summary(idata: az.InferenceData) -> Dict[str, float]:\n",
    "    rhat = az.rhat(idata).to_array().values\n",
    "    ess = az.ess(idata).to_array().values\n",
    "    return {\n",
    "        \"rhat_mean\": float(np.nanmean(rhat)),\n",
    "        \"ess_mean\": float(np.nanmean(ess)),\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
